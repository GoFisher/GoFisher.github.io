{
    "version": "https://jsonfeed.org/version/1",
    "title": "null",
    "description": "",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2021/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/Hive%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%93%8D%E4%BD%9C/",
            "url": "http://example.com/2021/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/Hive%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%93%8D%E4%BD%9C/",
            "title": "Hive数据类型操作",
            "date_published": "2021-12-01T16:49:21.872Z",
            "content_html": "<h1 id=\"hive数据类型操作\"><a class=\"anchor\" href=\"#hive数据类型操作\">#</a> Hive 数据类型操作</h1>\n<h2 id=\"hive内部表操作\"><a class=\"anchor\" href=\"#hive内部表操作\">#</a> Hive 内部表操作</h2>\n<h3 id=\"针对基本类型建表\"><a class=\"anchor\" href=\"#针对基本类型建表\">#</a> 针对基本类型建表</h3>\n<p>首先，在 master 机器的 <code>/export/data</code>  目录下创建 hivedata 目录，在改文件夹下创建 <code>user.txt</code> ，并添加如下数据内容：</p>\n<p><figure class=\"highlight txt\"><figcaption><span>测试数据内容</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1,allen,18</span><br><span class=\"line\">2,tom,23</span><br><span class=\"line\">3,jerry,28</span><br></pre></td></tr></table></figure></p>\n<p>具体操作如下：</p>\n<p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># mkdir -p /export/data/hivedata</span></span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># cd /export/data/hivedata/</span></span><br><span class=\"line\">[root@master hivedata]<span class=\"comment\"># vi user.txt </span></span><br><span class=\"line\">[root@master hivedata]<span class=\"comment\"># cat user.txt </span></span><br><span class=\"line\">1,allen,18</span><br><span class=\"line\">2,tom,23</span><br><span class=\"line\">3,jerry,28</span><br></pre></td></tr></table></figure></p>\n<p>启动 hadoop 和 hive, 具体如下操作</p>\n<p><figure class=\"highlight bash\"><figcaption><span>bash代码</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master data]<span class=\"comment\"># sh /usr/local/hadoop-2.6.5/sbin/start-all.sh</span></span><br><span class=\"line\">[root@master data]<span class=\"comment\"># sh /export/servers/apache-hive-1.2.1-bin/bin/hive</span></span><br></pre></td></tr></table></figure></p>\n<p><img data-src=\"https://gitee.com/gofisher/typora_pic/raw/master/images/image-20211201232425173.png\" alt=\"image-20211201232425173\" /></p>\n<p>在 hive 界面输入 <code>set hive.cli.print.current.db=true</code>  设置显示当前使用数据库，然后创建 <code>zjdf</code>  数据库，创建数据库后可以使用 <code>show databases</code>  命令进行查看，如果已经存在，可以使用 <code>drop database database_name cascade</code>  命令强制性删除，如果有表格，一定要添加 <code>cascade</code>  参数，用 <code>use</code>  切换到这个新建的数据库，并创建内部表 <code>t_user</code> , 具体操作如下：</p>\n<p><figure class=\"highlight plain\"><figcaption><span>hive界面命令</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive&gt; set hive.cli.print.current.db&#x3D;true;</span><br><span class=\"line\">hive (default)&gt; show databases;</span><br><span class=\"line\">OK</span><br><span class=\"line\">default</span><br><span class=\"line\">Time taken: 0.023 seconds, Fetched: 1 row(s)</span><br><span class=\"line\">hive (default)&gt; create database zjdf;</span><br><span class=\"line\">OK</span><br><span class=\"line\">Time taken: 0.182 seconds、  </span><br><span class=\"line\">hive (default)&gt; show databases;</span><br><span class=\"line\">OK</span><br><span class=\"line\">default</span><br><span class=\"line\">zjdf</span><br><span class=\"line\">Time taken: 0.016 seconds, Fetched: 2 row(s)</span><br><span class=\"line\">hive (default)&gt; use zjdf;</span><br><span class=\"line\">OK</span><br><span class=\"line\">Time taken: 0.024 seconds</span><br><span class=\"line\">hive (zjdf)&gt;</span><br></pre></td></tr></table></figure></p>\n<p><img data-src=\"https://gitee.com/gofisher/typora_pic/raw/master/images/image-20211201233838557.png\" alt=\"image-20211201233838557\" /></p>\n<p>针对 hivedata 目录准备的结构化文件 user.txt 先创建一个内部表 t_user，具体示例如下：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; create table t_user(id int,name string,age int) ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;,&#39;;</span><br><span class=\"line\">OK</span><br><span class=\"line\">Time taken: 0.561 seconds</span><br><span class=\"line\">hive (zjdf)&gt; show tables;</span><br><span class=\"line\">OK</span><br><span class=\"line\">t_user</span><br><span class=\"line\">Time taken: 0.037 seconds, Fetched: 1 row(s)</span><br><span class=\"line\">hive (zjdf)&gt; </span><br></pre></td></tr></table></figure></p>\n<p>创建成功后，通过 WEB UI 界面打开 Hive 内部表所在 HDFS 路径（默认 /user/hive/warehouse/zidj.db/t_user）进行查看，如下图所示。</p>\n<p><img data-src=\"https://gitee.com/gofisher/typora_pic/raw/master/images/image-20211201234130736.png\" alt=\"image-20211201234130736\" /></p>\n<p>复制 master 终端，然后点击选项卡排列，可以达到左右分屏的效果，如下所示：</p>\n<p><img data-src=\"https://gitee.com/gofisher/typora_pic/raw/master/images/image-20211201234439467.png\" alt=\"image-20211201234439467\" /></p>\n<p>将准备好的 user.txt 移动到 hadoop 对应的 t_user 表的路径中，具体操作如下：</p>\n<p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master hivedata]<span class=\"comment\"># hadoop fs -put user.txt /user/hive/warehouse/zjdf.db/t_user</span></span><br><span class=\"line\">21/12/01 10:05:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class=\"keyword\">for</span> your platform... using builtin-java classes <span class=\"built_in\">where</span> applicable</span><br><span class=\"line\">[root@master hivedata]<span class=\"comment\">#</span></span><br></pre></td></tr></table></figure></p>\n<p>刷新 Hadoop 文件系统，如下图所示：</p>\n<p><img data-src=\"https://gitee.com/gofisher/typora_pic/raw/master/images/image-20211201234942510.png\" alt=\"image-20211201234942510\" /></p>\n<p>在 hive 界面中查询 t_user 表数据，发现表中已经存在数据，具体命令如下：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; select * from t_user;</span><br><span class=\"line\">OK</span><br><span class=\"line\">1\tallen\t18</span><br><span class=\"line\">2\ttom\t23</span><br><span class=\"line\">3\tjerry\t28</span><br><span class=\"line\">Time taken: 0.476 seconds, Fetched: 3 row(s)</span><br><span class=\"line\">hive (zjdf)&gt;</span><br></pre></td></tr></table></figure></p>\n<p><img data-src=\"https://gitee.com/gofisher/typora_pic/raw/master/images/image-20211201235147810.png\" alt=\"image-20211201235147810\" /></p>\n<h3 id=\"针对复杂类型建表\"><a class=\"anchor\" href=\"#针对复杂类型建表\">#</a> 针对复杂类型建表</h3>\n<p>例如，现有结构化数据文件 student.txt，文件内容如下所示。</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1,zhangsan,唱歌:非常喜欢-跳舞:喜欢-游泳:一般般</span><br><span class=\"line\">2,lisi,打游戏:非常喜欢-篮球:不喜欢</span><br></pre></td></tr></table></figure></p>\n<p>通过对 student.txt 文件内容分析得出，可以设计为 3 列字段，即编号、姓名、兴趣，其中编号可以为 int 类型，姓名可以为 string 类型，而兴趣列还需要进一步分隔为 Map 类型，因此在创建 student.txt 文件对应的内部表语句如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; create table t_student(id int,name string,hobby map&lt;string,string&gt;) row format delimited fields terminated by &#39;,&#39;  collection items terminated by &#39;-&#39; map keys terminated by &#39;:&#39;;</span><br><span class=\"line\">OK</span><br><span class=\"line\">Time taken: 0.064 seconds</span><br><span class=\"line\">hive (zjdf)&gt; show tables;</span><br><span class=\"line\">OK</span><br><span class=\"line\">t_student</span><br><span class=\"line\">t_user</span><br><span class=\"line\">Time taken: 0.03 seconds, Fetched: 2 row(s)</span><br><span class=\"line\">hive (zjdf)&gt;</span><br></pre></td></tr></table></figure></p>\n<p>上述建表语句中，通过对 student.txt 文件结构化文件的分析，先通过逗号 “，” 对多个字段 fields 进行分隔；接着，针对 hobby 字段列，通过横线 “-” 进行集合列分隔；最后，再针对每一个爱好，通过冒号 “：” 进行分隔为最终的 “key：value” 形式。执行上述建表语句后，就会在默认的 /user/hive/warehouse/zjdf.db 文件夹下生成一个 t_student 文件夹。如下图所示：</p>\n<p><img data-src=\"https://gitee.com/gofisher/typora_pic/raw/master/images/image-20211201235638917.png\" alt=\"image-20211201235638917\" /></p>\n<p>此时，还必须将前面的结构化文件 student.txt 上传到该文件夹下进行映射，才能生成对应的内部表数据，上传完成后再次查询生成的 t_student 表信息。</p>\n<p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master hivedata]<span class=\"comment\"># vi student.txt</span></span><br><span class=\"line\">[root@master hivedata]<span class=\"comment\"># cat student.txt </span></span><br><span class=\"line\">1,zhangsan,唱歌:非常喜欢-跳舞:喜欢-游泳:一般般</span><br><span class=\"line\">2,lisi,打游戏:非常喜欢-篮球:不喜欢</span><br><span class=\"line\">[root@master hivedata]<span class=\"comment\"># hadoop fs -put student.txt /user/hive/warehouse/zjdf.db/t_student</span></span><br><span class=\"line\">21/12/01 10:15:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class=\"keyword\">for</span> your platform... using builtin-java classes <span class=\"built_in\">where</span> applicable</span><br><span class=\"line\">[root@master hivedata]<span class=\"comment\">#</span></span><br></pre></td></tr></table></figure></p>\n<p>再次在 hive 中查询 t_student 数据表格，如下图所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; select * from t_student;</span><br><span class=\"line\">OK</span><br><span class=\"line\">1\tzhangsan\t&#123;&quot;唱歌&quot;:&quot;非常喜欢&quot;,&quot;跳舞&quot;:&quot;喜欢&quot;,&quot;游泳&quot;:&quot;一般般&quot;&#125;</span><br><span class=\"line\">2\tlisi\t&#123;&quot;打游戏&quot;:&quot;非常喜欢&quot;,&quot;篮球&quot;:&quot;不喜欢&quot;&#125;</span><br><span class=\"line\">Time taken: 0.082 seconds, Fetched: 2 row(s)</span><br><span class=\"line\">hive (zjdf)&gt; </span><br></pre></td></tr></table></figure></p>\n<h2 id=\"hive外部表操作\"><a class=\"anchor\" href=\"#hive外部表操作\">#</a> Hive 外部表操作</h2>\n<p>内部表，即不添加关键字 External，内部表与结构化数据文件要想产生关系映射，那么数据文件就必须在指定的内部表文件夹下，而当遇到大文件的情况时，移动数据文件非常耗时，这就需要我们来创建外部表，因为它不需要移动结构化数据文件。下面我们通过一个小案例来，对外部表进行讲解。</p>\n<p>现有结构化数据文件 student.txt，且数据内容如文件所示。</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">95001,李勇,男,20,CS</span><br><span class=\"line\">95002,刘晨,女,19,IS</span><br><span class=\"line\">95003,王敏,女,22,MA</span><br><span class=\"line\">95004,张立,男,19,IS</span><br><span class=\"line\">95005,刘刚,男,18,MA</span><br><span class=\"line\">95006,孙庆,男,23,CS</span><br><span class=\"line\">95007,易思玲,女,19,MA</span><br><span class=\"line\">95008,李娜,女,18,CS</span><br><span class=\"line\">95009,梦圆圆,女,18,MA</span><br><span class=\"line\">95010,孔小涛,男,19,CS</span><br><span class=\"line\">95011,包小柏,男,18,MA</span><br><span class=\"line\">95012,孙花,女,20,CS</span><br><span class=\"line\">95013,冯伟,男,21,CS</span><br><span class=\"line\">95014,王小丽,女,19,CS</span><br><span class=\"line\">95015,王君,男,18,MA</span><br><span class=\"line\">95016,钱国,男,21,MA</span><br><span class=\"line\">95017,王风娟,女,18,IS</span><br><span class=\"line\">95018,王一,女,19,IS</span><br><span class=\"line\">95019,邢小丽,女,19,IS</span><br><span class=\"line\">95020,赵钱,男,21,IS</span><br><span class=\"line\">95021,周二,男,17,MA</span><br><span class=\"line\">95022,郑明,男,20,MA</span><br></pre></td></tr></table></figure></p>\n<p>首先，我们将 student.txt 文件上传至 HDFS 上的 /stu 路径下，用来模拟生产环境下的数据文件，具体命令如下所示：</p>\n<p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># vi student.txt </span></span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># hadoop fs -mkdir /stu</span></span><br><span class=\"line\">21/12/01 10:21:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class=\"keyword\">for</span> your platform... using builtin-java classes <span class=\"built_in\">where</span> applicable</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># hadoop fs -put student.txt /stu</span></span><br><span class=\"line\">21/12/01 10:22:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class=\"keyword\">for</span> your platform... using builtin-java classes <span class=\"built_in\">where</span> applicable</span><br><span class=\"line\">[root@master ~]<span class=\"comment\">#</span></span><br></pre></td></tr></table></figure></p>\n<p>在 hive 中创建外部表</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; create external table student_ext(Sno int,Sname string,Sex string,Sage int,Sdept string) row format delimited fields terminated by &#39;,&#39; location &#39;&#x2F;stu&#39;;</span><br><span class=\"line\">OK</span><br><span class=\"line\">Time taken: 0.041 seconds</span><br><span class=\"line\">hive (zjdf)&gt; show tables;</span><br><span class=\"line\">OK</span><br><span class=\"line\">student_ext</span><br><span class=\"line\">t_student</span><br><span class=\"line\">t_user</span><br><span class=\"line\">Time taken: 0.027 seconds, Fetched: 3 row(s)</span><br><span class=\"line\">hive (zjdf)&gt; </span><br></pre></td></tr></table></figure></p>\n<p>从结果发现，student_ext 外部表已经创建成功，最后，HQL（HiveQL）对数据表的内容的查看、增加、删除以及修改的语句均与 SQL 语句一致。下面以查看数据表内容为例进行演示，具体语法如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; select * from student_ext;</span><br></pre></td></tr></table></figure></p>\n<p>结果如下</p>\n<p><img data-src=\"https://gitee.com/gofisher/typora_pic/raw/master/images/image-20211202001146733.png\" alt=\"image-20211202001146733\" /></p>\n<p><strong>小提示：Hive 创建内部表时，会将数据移动到数据库指向的路径；创建外部表时，仅记录数据所在的路径，不会对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据</strong></p>\n<h2 id=\"hive分区表操作\"><a class=\"anchor\" href=\"#hive分区表操作\">#</a> Hive 分区表操作</h2>\n<p>分区表是按照属性在文件夹层面给文件更好的管理，实际上就是对应一个 HDFS 文件系统上的独立文件夹，该文件夹下是该分区所有的数据文件。Hive 中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集。在查询时通过 WHERE 子句中的表达式选择查询指定的分区，这样的查询效率会提高很多。Hive 分区表一共有两种，分别为普通分区和动态分区，我们下面就要对其分别进行介绍。</p>\n<h3 id=\"hive普通分区\"><a class=\"anchor\" href=\"#hive普通分区\">#</a> Hive 普通分区</h3>\n<p>创建分区表分为两种，一种是单分区，也就是说在表文件夹目录下只有一级文件夹目录。另外一种是多分区，表文件夹下出现多文件夹嵌套模式，现在我们只针对单分区进行详解，若想学习多分区可以参考官网的官方文档。</p>\n<p>现有结构化数据文件 user_p.txt，文件中的数据内容如文件所示。</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1,allen</span><br><span class=\"line\">2,tom</span><br><span class=\"line\">3,jerry</span><br></pre></td></tr></table></figure></p>\n<p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># mkdir -p /export/data/hivedata/</span></span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># cd /export/data/hivedata/</span></span><br><span class=\"line\">[root@master hivedata]<span class=\"comment\"># ll</span></span><br><span class=\"line\">total 8</span><br><span class=\"line\">-rw-r--r--. 1 root root 109 Dec  1 10:14 student.txt</span><br><span class=\"line\">-rw-r--r--. 1 root root  31 Dec  1 09:43 user.txt</span><br><span class=\"line\">[root@master hivedata]<span class=\"comment\"># vi user_p.txt</span></span><br><span class=\"line\">[root@master hivedata]<span class=\"comment\">#</span></span><br></pre></td></tr></table></figure></p>\n<p>首先，创建分区表。语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; create table t_user_p(id int, name string) partitioned by (country string) row format delimited fields terminated by &#39;,&#39;;</span><br></pre></td></tr></table></figure></p>\n<p><img data-src=\"https://gitee.com/gofisher/typora_pic/raw/master/images/image-20211202002144514.png\" alt=\"image-20211202002144514\" /></p>\n<p>其次，加载数据是将数据文件移动到与 Hive 表对应的位置，从本地（Linux）复制或移动到 HDFS 文件系统的操作。由于分区表在映射数据时不能使用 Hadoop 命令移动文件，需要使用 Load 命令，其语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LOAD DATA [LOCAL] INPATH &#39;filepath&#39; [OVERWRITE] </span><br><span class=\"line\">INTO TABLE table_name [PARTITION (partcol1&#x3D;val1, partcol2&#x3D;val2 ...)]</span><br></pre></td></tr></table></figure></p>\n<p>Load Data 是 HQL 固定的数据装载语句，下面针对部分关键字进行讲解。</p>\n<ul>\n<li>Filepath：它可以引用一个文件（在这种情况下，Hive 将文件移动到表所对应的目录中），或者它可以是一个目录（在这种情况下，Hive 将把该目录中的所有文件移动到表所对应的目录中）。它可以是相对路径、绝对路径以及完整的 URI。</li>\n<li>Local：如果指定了 Local 键字，Load 命令将在本地文件系统（Hive 服务启动方）中查找文件路径，将其复制到对应的 HDFS 路径下；如果没有指定 Local 关键字，它将会从 HDFS 中移动数据文件至对应的表路径下。</li>\n<li>Overwrite：如果使用了 Overwrite 关键字，当加载数据时目标表或分区中的内容会被删除，然后再将 filepath 指向的文件或目录中的内容添加到表或分区中。简单的说就是覆盖表中已有数据；若不添加该关键字，则表示追加数据内容。</li>\n</ul>\n<p>加载数据操作的语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; load data local inpath &#39;&#x2F;export&#x2F;data&#x2F;hivedata&#x2F;user_p.txt&#39; into table t_user_p partition(country&#x3D;&#39;USA&#39;);</span><br><span class=\"line\">Loading data to table zjdf.t_user_p partition (country&#x3D;USA)</span><br><span class=\"line\">Partition zjdf.t_user_p&#123;country&#x3D;USA&#125; stats: [numFiles&#x3D;1, numRows&#x3D;0, totalSize&#x3D;22, rawDataSize&#x3D;0]</span><br><span class=\"line\">OK</span><br><span class=\"line\">Time taken: 0.618 seconds</span><br><span class=\"line\">hive (zjdf)&gt;</span><br></pre></td></tr></table></figure></p>\n<p>从上述语句看出，Load Data 表示装载数据，Inpath 表示数据文件所在的本地系统路径，partition（country=‘USA’）为指定的分区，它需要与建表时设置的分区字段保持一致。执行完上述命令后，查看表内容的数据，效果如图所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; select * from t_user_p;</span><br><span class=\"line\">OK</span><br><span class=\"line\">1\tallen\tUSA</span><br><span class=\"line\">2\ttom\tUSA</span><br><span class=\"line\">3\tjerry\tUSA</span><br><span class=\"line\">Time taken: 0.274 seconds, Fetched: 3 row(s)</span><br><span class=\"line\">hive (zjdf)&gt; </span><br></pre></td></tr></table></figure></p>\n<h3 id=\"hive动态分区\"><a class=\"anchor\" href=\"#hive动态分区\">#</a> Hive 动态分区</h3>\n<p>上面介绍了 Hive 普通分区的创建和 Load 命令加载数据的操作。在默认情况下，我们加载数据时，需要手动的设置分区字段，并且针对一个分区就要写一个插入语句。如果源数据量很大时（例如，现有许多日志文件，要求按照日期作为分区字段，在插入数据的时候无法手动的添加分区），就可以利用 Hive 提供的动态分区，可以简化插入数据时的繁琐操作，若想实现动态分区，则需要开启动态分区功能，具体命令如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive&gt; set hive.exec.dynamic.partition&#x3D;true;</span><br><span class=\"line\">hive&gt; set hive.exec.dynamic.partition.mode&#x3D;nonstrict;</span><br></pre></td></tr></table></figure></p>\n<p>Hive 默认是不支持动态分区的，因此 hive.exec.dynamic.partition 默认值为 false，需要启动动态分区功能，可以将该参数设置为 true；其中 hive.exec.dynamic.partition.mode 的默认值是 strict，表示必须指定至少一个分区为静态分区，将此参数修改为 nonstrict，表示允许所有的分区字段都可以使用动态分区。</p>\n<p>在 Hive 中 insert 语句是用于动态插入数据的，不同的是它主要是结合 select 查询语句使用，且非常适用于动态分区插入数据，语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive&gt; insert overwrite table table_name </span><br><span class=\"line\">partition (partcol1[&#x3D;val1], partcol2[&#x3D;val2] ...) </span><br><span class=\"line\">select_statement FROM from_statement</span><br></pre></td></tr></table></figure></p>\n<p>现有原始表的结构化数据文件 dynamic_partition_table.txt，内容数据如文件所示。</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">2018-05-10,ip1</span><br><span class=\"line\">2018-05-10,ip2</span><br><span class=\"line\">2018-06-14,ip3</span><br><span class=\"line\">2018-06-14,ip4</span><br><span class=\"line\">2018-06-15,ip1</span><br><span class=\"line\">2018-06-15,ip2</span><br></pre></td></tr></table></figure></p>\n<p><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master hivedata]<span class=\"comment\"># vi dynamic_partition_table.txt</span></span><br><span class=\"line\">[root@master hivedata]<span class=\"comment\"># cat dynamic_partition_table.txt </span></span><br><span class=\"line\">2018-05-10,ip1</span><br><span class=\"line\">2018-05-10,ip2</span><br><span class=\"line\">2018-06-14,ip3</span><br><span class=\"line\">2018-06-14,ip4</span><br><span class=\"line\">2018-06-15,ip1</span><br><span class=\"line\">2018-06-15,ip2</span><br><span class=\"line\">[root@master hivedata]<span class=\"comment\">#</span></span><br></pre></td></tr></table></figure></p>\n<p>现在我们通过一个案例进行演示动态分区的数据插入操作。将 dynamic_partition_table 中的数据按照时间（day），插入到目标表 d_p_t 的相应分区中。</p>\n<p>首先，创建原始表。语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; create table dynamic_partition_table(day string,ip string) row format delimited fields terminated by &quot;,&quot;;</span><br><span class=\"line\">OK</span><br><span class=\"line\">Time taken: 0.05 seconds</span><br><span class=\"line\">hive (zjdf)&gt; show tables;</span><br><span class=\"line\">OK</span><br><span class=\"line\">dynamic_partition_table</span><br><span class=\"line\">student_ext</span><br><span class=\"line\">t_student</span><br><span class=\"line\">t_user</span><br><span class=\"line\">t_user_p</span><br><span class=\"line\">Time taken: 0.033 seconds, Fetched: 5 row(s)</span><br></pre></td></tr></table></figure></p>\n<p>其次，加载数据文件至原始表，语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; load data local inpath &#39;&#x2F;export&#x2F;data&#x2F;hivedata&#x2F;dynamic_partition_table.txt&#39; into table dynamic_partition_table;</span><br><span class=\"line\">Loading data to table zjdf.dynamic_partition_table</span><br><span class=\"line\">Table zjdf.dynamic_partition_table stats: [numFiles&#x3D;1, totalSize&#x3D;90]</span><br><span class=\"line\">OK</span><br><span class=\"line\">Time taken: 0.234 seconds</span><br><span class=\"line\">hive (zjdf)&gt; select * from dynamic_partition_table;</span><br><span class=\"line\">OK</span><br><span class=\"line\">2018-05-10\tip1</span><br><span class=\"line\">2018-05-10\tip2</span><br><span class=\"line\">2018-06-14\tip3</span><br><span class=\"line\">2018-06-14\tip4</span><br><span class=\"line\">2018-06-15\tip1</span><br><span class=\"line\">2018-06-15\tip2</span><br><span class=\"line\">Time taken: 0.062 seconds, Fetched: 6 row(s)</span><br><span class=\"line\">hive (zjdf)&gt; </span><br></pre></td></tr></table></figure></p>\n<p>再次，创建目标表，语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; create table d_p_t(ip string) partitioned by (month string,day string);</span><br><span class=\"line\">OK</span><br><span class=\"line\">Time taken: 0.045 seconds</span><br><span class=\"line\">hive (zjdf)&gt; show tables;</span><br><span class=\"line\">OK</span><br><span class=\"line\">d_p_t</span><br><span class=\"line\">dynamic_partition_table</span><br><span class=\"line\">student_ext</span><br><span class=\"line\">t_student</span><br><span class=\"line\">t_user</span><br><span class=\"line\">t_user_p</span><br><span class=\"line\">Time taken: 0.023 seconds, Fetched: 6 row(s)</span><br><span class=\"line\">hive (zjdf)&gt;</span><br></pre></td></tr></table></figure></p>\n<p>依次，动态插入，语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; insert overwrite table d_p_t partition (month,day) select ip,substr(day,1,7) as month,day from dynamic_partition_table;</span><br></pre></td></tr></table></figure></p>\n<p><img data-src=\"C:/Users/yujz/AppData/Roaming/Typora/typora-user-images/image-20211202004106877.png\" alt=\"image-20211202004106877\" /></p>\n<p>最后，查看目标表中的分区数据，语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive (zjdf)&gt; show partitions d_p_t;</span><br><span class=\"line\">OK</span><br><span class=\"line\">month&#x3D;2018-05&#x2F;day&#x3D;2018-05-10</span><br><span class=\"line\">month&#x3D;2018-06&#x2F;day&#x3D;2018-06-14</span><br><span class=\"line\">month&#x3D;2018-06&#x2F;day&#x3D;2018-06-15</span><br><span class=\"line\">Time taken: 0.449 seconds, Fetched: 3 row(s)</span><br><span class=\"line\">hive (zjdf)&gt;</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"hive桶表操作\"><a class=\"anchor\" href=\"#hive桶表操作\">#</a> Hive 桶表操作</h2>\n<p>为了将表进行更细粒度的范围划分，我们可以创建桶表。桶表，是根据某个属性字段把数据分成几个桶（我们这里设置为 4，默认值是 - 1，可自定义），也就是在文件的层面上把数据分开。下面通过一个案例进行桶表相关操作的演示。</p>\n<p>首先，我们先开启分桶功能，命令如下所示。</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive&gt; set hive.enforce.bucketing &#x3D; true;</span><br><span class=\"line\">&#x2F;&#x2F;由于HQL最终会转成MR程序，所以分桶数与ReduceTask数保持一致，</span><br><span class=\"line\">&#x2F;&#x2F;从而产生相应的文件个数</span><br><span class=\"line\">hive&gt; set mapreduce.job.reduces&#x3D;4;</span><br></pre></td></tr></table></figure></p>\n<p>其次，创建桶表，语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive&gt; create table stu_buck(Sno int,Sname string,Sex string,Sage int,Sdept string) clustered by(Sno) into 4 buckets row format delimited fields terminated by &#39;,&#39;;</span><br></pre></td></tr></table></figure></p>\n<p>执行上述语句后，桶表 stu_buck 创建完成，并且以学生编号（Sno）分为 4 个桶，以 “，” 为分隔符的桶表。</p>\n<p>再次，在 HDFS 的 /stu/ 目录下已有结构化数据文件 student.txt，我们需要将 student.txt 文件的复制到 /hivedata 目录下。然后，加载数据到桶表中，由于分桶表加载数据时，不能使用 Load Data 方式导入数据（原因在于该 Load Data 本质上是对数据文件进行复制或移动到 Hive 表所对应的地址中），因此在分桶表导入数据时需要创建临时的 student 表，该表与 stu_buck 表的字段必须一致，语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive&gt; create table student_tmp(Sno int,Sname string,Sex string,Sage int,Sdept string) </span><br><span class=\"line\">row format delimited fields terminated by &#39;,&#39;;</span><br></pre></td></tr></table></figure></p>\n<p>依次，加载数据至 student 表，语法格式如下所示</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive&gt; load data local inpath &#39;&#x2F;hivedata&#x2F;student.txt&#39; into table student_tmp;</span><br></pre></td></tr></table></figure></p>\n<p>最后，将数据导入 stu_buck 表，语法格式如下所示：</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hive&gt; insert overwrite table stu_buck select * from student_tmp cluster by(Sno);</span><br></pre></td></tr></table></figure></p>\n<p>总体来说，分桶表是把表所映射的结构化数据分得更细致，且分桶规则与 MapReduce 分区规则一致，Hive 采用对目标列值进行哈希运算，得到哈希值再与桶个数取模的方式决定数据的归并，从而看出 Hive 与 MapReduce 存在紧密联系。使用分桶可以提高查询效率，例如执行 Join 操作时，两个表有相同的列字段，如果对这两张表都采取了分桶操作，那么就可以减少 Join 操作时的数据量，从而提高查询效率。它还能够在处理大规模数据集时，选择小部分数据集进行抽样运算，从而减少资源浪费。</p>\n",
            "tags": [
                "大数据技术与应用",
                "Hive"
            ]
        },
        {
            "id": "http://example.com/2021/11/30/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/Hive%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/",
            "url": "http://example.com/2021/11/30/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/Hive%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/",
            "title": "Hive安装教程",
            "date_published": "2021-11-30T14:51:49.025Z",
            "content_html": "<h1 id=\"hive的安装\"><a class=\"anchor\" href=\"#hive的安装\">#</a> Hive 的安装</h1>\n<p>​\t本地和远程模式安装配置方式大致相同，本质上是将 Hive 默认的元数据存储介质由自带的 Derby 数据库替换为 MySQL 数据库，这样无论在任何目录下以任何方式启动 Hive，只要连接的是同一台 Hive 服务，那么所有节点访问的元数据信息是一致的，从而实现元数据的共享。下面就以本地模式为例，讲解安装过程。<br />\n​\t本地模式的 Hive 安装主要包括两个步骤：首先安装 MySQL 服务，再安装 Hive。具体步骤如下：</p>\n<h2 id=\"安装mysql服务\"><a class=\"anchor\" href=\"#安装mysql服务\">#</a> 安装 MySQL 服务</h2>\n<pre><code>MySQL安装方式有许多种，可以直接解压安装包进行相关配置，也可以选择在线安装，本节选用在线安装MySQL方式。在线安装MySQL的具体指令和说明如下：\n</code></pre>\n<h3 id=\"切换yum源\"><a class=\"anchor\" href=\"#切换yum源\">#</a> 切换 yum 源</h3>\n<p><figure class=\"highlight bash\"><figcaption><span>命令行提示符</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># vi /etc/yum.repos.d/CentOS-Base.repo</span></span><br></pre></td></tr></table></figure><br />\n 修改镜像的内容，一定要确定修改的是正确并且完整，修改的文本内容如下，删除的时候可以在命令模式下输入【100dd】快速删除，操作演示如下：<br />\n<img data-src=\"https://media.giphy.com/media/CdThtgNMrtTPh23QKN/source.gif\" alt=\"\" /><br />\n​\t需要修改的 yum 镜像文件如下也可以在下发的文件中进行复制：<br />\n<figure class=\"highlight txt\"><figcaption><span>yum镜像文件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[base]</span><br><span class=\"line\">name=CentOS-6.10 - Base - mirrors.aliyun.com</span><br><span class=\"line\">failovermethod=priority</span><br><span class=\"line\">baseurl=http://mirrors.aliyun.com/centos-vault/6.10/os/$basearch/</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6</span><br><span class=\"line\">#released updates </span><br><span class=\"line\">[updates]</span><br><span class=\"line\">name=CentOS-6.10 - Updates - mirrors.aliyun.com</span><br><span class=\"line\">failovermethod=priority</span><br><span class=\"line\">baseurl=http://mirrors.aliyun.com/centos-vault/6.10/updates/$basearch/</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6</span><br><span class=\"line\">#additional packages that may be useful</span><br><span class=\"line\">[extras]</span><br><span class=\"line\">name=CentOS-6.10 - Extras - mirrors.aliyun.com</span><br><span class=\"line\">failovermethod=priority</span><br><span class=\"line\">baseurl=http://mirrors.aliyun.com/centos-vault/6.10/extras/$basearch/</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6</span><br><span class=\"line\">#additional packages that extend functionality of existing packages</span><br><span class=\"line\">[centosplus]</span><br><span class=\"line\">name=CentOS-6.10 - Plus - mirrors.aliyun.com</span><br><span class=\"line\">failovermethod=priority</span><br><span class=\"line\">baseurl=http://mirrors.aliyun.com/centos-vault/6.10/centosplus/$basearch/</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">enabled=0</span><br><span class=\"line\">gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6</span><br><span class=\"line\">#contrib - packages by Centos Users</span><br><span class=\"line\">[contrib]</span><br><span class=\"line\">name=CentOS-6.10 - Contrib - mirrors.aliyun.com</span><br><span class=\"line\">failovermethod=priority</span><br><span class=\"line\">baseurl=http://mirrors.aliyun.com/centos-vault/6.10/contrib/$basearch/</span><br><span class=\"line\">gpgcheck=1</span><br><span class=\"line\">enabled=0</span><br><span class=\"line\">gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"清除yum缓存\"><a class=\"anchor\" href=\"#清除yum缓存\">#</a> 清除 yum 缓存</h3>\n<p><figure class=\"highlight bash\"><figcaption><span>Bash命令</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># yum clean all</span></span><br></pre></td></tr></table></figure><br />\n<img data-src=\"https://i.loli.net/2021/11/30/jdJSKHGmwD97g5b.jpg\" alt=\"hive1.jpg\" /></p>\n<h3 id=\"在线安装mysql软件\"><a class=\"anchor\" href=\"#在线安装mysql软件\">#</a> 在线安装 MySql 软件</h3>\n<p><figure class=\"highlight bash\"><figcaption><span>Bash命令</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># yum -y install mysql-server</span></span><br></pre></td></tr></table></figure><br />\n​\t安装完成后，如图片所示，则数据库安装完成：<br />\n<img data-src=\"https://i.loli.net/2021/11/30/oPD2nesHX7tJ9jy.jpg\" alt=\"hive2.jpg\" /></p>\n<h3 id=\"启动mysql服务\"><a class=\"anchor\" href=\"#启动mysql服务\">#</a> 启动 mysql 服务</h3>\n<p><figure class=\"highlight bash\"><figcaption><span>Bash命令</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># service mysqld start</span></span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># chkconfig mysqld on</span></span><br></pre></td></tr></table></figure><br />\n<img data-src=\"https://i.loli.net/2021/11/30/ZCIJv4xWKR53Dap.jpg\" alt=\"hive3.jpg\" /><br />\n​\t上述指令中，首先通过 “yum install” 命令下载并安装 MySQL 程序，并且启动 MySQL 服务，然后就可以使用 MySQL 命令连接到 MySQL 客户端。<strong>需要注意的是，上述安装与启动 MySQL 程序仅限于 Centos6 中使用。</strong><br />\n<strong>说明</strong>：如果是 CentOS7 可以参考：<span class=\"exturl\" data-url=\"aHR0cHM6Ly9zZWdtZW50ZmF1bHQuY29tL2EvMTE5MDAwMDAyMjI0NTg1OQ==\">Centos7 在线安装和配置 MySQL5.7 - SegmentFault 思否</span></p>\n<h3 id=\"修改登录mysql用户名和密码bash\"><a class=\"anchor\" href=\"#修改登录mysql用户名和密码bash\">#</a> 修改登录 MySQL 用户名和密码 bash</h3>\n<p>​\t进入 mysql 数据库<br />\n <figure class=\"highlight bash\"><figcaption><span>Bash命令</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># mysql</span></span><br></pre></td></tr></table></figure><br />\n<img data-src=\"https://i.loli.net/2021/11/30/6f2azJbwBKVpAsn.jpg\" alt=\"hive4.jpg\" /></p>\n<p><figure class=\"highlight plain\"><figcaption><span>数据库界面</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; set password for root@localhost&#x3D;password(&#39;123456&#39;);</span><br><span class=\"line\">Query OK, 0 rows affected (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39; WITH GRANT OPTION;</span><br><span class=\"line\">Query OK, 0 rows affected (0.00 sec)</span><br><span class=\"line\"></span><br><span class=\"line\">mysql&gt; FLUSH PRIVILEGES;</span><br><span class=\"line\">Query OK, 0 rows affected (0.00 sec)</span><br></pre></td></tr></table></figure><br />\n​\t结果显示如下：<br />\n<img data-src=\"https://i.loli.net/2021/11/30/aHubCKIYEwZ1RVc.jpg\" alt=\"hive5.jpg\" /><br />\n​\t运行结束后，【ctrl+c】退出 mysql 数据库！</p>\n<h2 id=\"安装hive\"><a class=\"anchor\" href=\"#安装hive\">#</a> 安装 Hive</h2>\n<h3 id=\"上传hive安装包并解压\"><a class=\"anchor\" href=\"#上传hive安装包并解压\">#</a> 上传 Hive 安装包并解压</h3>\n<p>​\t创建出存放 hive 软件的目录和安装的目录，切换至 <code>software</code>  目录，将软件包拖放至此，然后在进行解压到 <code>servers</code> 。<br />\n<figure class=\"highlight bash\"><figcaption><span>Bash命令</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># mkdir -p /export/software/</span></span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># mkdir -p /export/servers/</span></span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># cd /export/software/</span></span><br><span class=\"line\">[root@master software]</span><br></pre></td></tr></table></figure><br />\n​\t打开 <code>新建文件传输</code> 图标，如下所示：<br />\n<img data-src=\"https://i.loli.net/2021/11/30/C2ZpIGaFubx1w5E.jpg\" alt=\"hive6.jpg\" /><br />\n<figure class=\"highlight bash\"><figcaption><span>Bash命令</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master software]<span class=\"comment\"># tar -zxvf apache-hive-1.2.1-bin.tar.gz -C /export/servers/</span></span><br></pre></td></tr></table></figure><br />\n​\t<strong>一定要确定是解压成功之后在操作，解压成功会有如下信息显示。</strong><br />\n<img data-src=\"https://i.loli.net/2021/11/30/boZ3HIk2WvY8Bgq.jpg\" alt=\"hive7.jpg\" /></p>\n<h3 id=\"修改配置文件\"><a class=\"anchor\" href=\"#修改配置文件\">#</a> 修改配置文件</h3>\n<p>​\t首先，切换目录到 hive 配置文件目录下，由于 Hive 安装包 conf 目录下，没有提供 hive-site.xml 文件，这里需要创建并编辑一个 hive-site.xml 配置文件，具体内容如下所示：<br />\n<figure class=\"highlight bash\"><figcaption><span>Bash命令</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master servers]<span class=\"comment\"># cd /export/servers/apache-hive-1.2.1-bin/conf/</span></span><br><span class=\"line\">[root@master conf]<span class=\"comment\"># vi hive-site.xml</span></span><br></pre></td></tr></table></figure><br />\n​\t将以下配置信息粘贴进去，并保存退出。<br />\n<figure class=\"highlight xml\"><figcaption><span>hive配置文件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>Mysql连接协议<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>com.mysql.jdbc.Driver<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>JDBC连接驱动<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>root<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>用户名<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">value</span>&gt;</span>123456<span class=\"tag\">&lt;/<span class=\"name\">value</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">description</span>&gt;</span>密码<span class=\"tag\">&lt;/<span class=\"name\">description</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span>\t </span><br></pre></td></tr></table></figure></p>\n<h3 id=\"依赖包的更换\"><a class=\"anchor\" href=\"#依赖包的更换\">#</a> 依赖包的更换</h3>\n<p>​\t将桌面的 <code>mysql-connector-java-5.1.21.jar</code> Mysql 驱动包放到 <code>/export/servers/apache-hive-1.2.1-bin/lib</code>  目录中，如下图所示：<br />\n<img data-src=\"https://i.loli.net/2021/11/30/O9w4fybUYhj7vsF.jpg\" alt=\"hive8.jpg\" /><br />\n​\t开两个 <code>新建文件传输窗口</code> 将 Hadoop 中的 Jline 包替换成 hive 包中 Jline 包，并将<strong> Hadoop 中旧的 Jline 包版本删除，一定要删除，否则还是旧版本。</strong><br />\n<img data-src=\"https://i.loli.net/2021/11/30/UE6eOuVZBP9Lzts.jpg\" alt=\"hive9.jpg\" /><br />\n<strong> 注意：如果拖不过去的话，就先将 Jline 包拖放到桌面，然后再放进 Hadoop 文件夹中。</strong></p>\n<h3 id=\"启动hadoop集群\"><a class=\"anchor\" href=\"#启动hadoop集群\">#</a> 启动 Hadoop 集群</h3>\n<p><figure class=\"highlight bash\"><figcaption><span>Bash命令</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master conf]<span class=\"comment\"># sh /usr/local/hadoop-2.6.5/sbin/start-all.sh</span></span><br><span class=\"line\">WARNING: HADOOP_SECURE_DN_USER has been replaced by HDFS_DATANODE_SECURE_USER. Using value of HADOOP_SECURE_DN_USER.</span><br><span class=\"line\">Starting namenodes on [master]</span><br><span class=\"line\">Last login: Thu Nov 25 05:04:04 CST 2021 from 192.168.128.1 on pts/0</span><br><span class=\"line\">Starting datanodes</span><br><span class=\"line\">Last login: Thu Nov 25 05:43:45 CST 2021 on pts/0</span><br><span class=\"line\">Starting secondary namenodes [master]</span><br><span class=\"line\">Last login: Thu Nov 25 05:43:48 CST 2021 on pts/0</span><br><span class=\"line\">Starting resourcemanager</span><br><span class=\"line\">Last login: Thu Nov 25 05:43:53 CST 2021 on pts/0</span><br><span class=\"line\">Starting nodemanagers</span><br><span class=\"line\">Last login: Thu Nov 25 05:44:00 CST 2021 on pts/0</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># jps</span></span><br><span class=\"line\">1824 SecondaryNameNode</span><br><span class=\"line\">2375 Jps</span><br><span class=\"line\">2059 ResourceManager</span><br><span class=\"line\">1566 NameNode</span><br></pre></td></tr></table></figure><br />\n 初始化 Mysql 元数据<br />\n <figure class=\"highlight bash\"><figcaption><span>Bash命令</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master conf]<span class=\"comment\"># cd /export/servers/apache-hive-1.2.1-bin/bin/</span></span><br><span class=\"line\">[root@master bin]<span class=\"comment\"># ./schematool -dbType mysql -initSchema</span></span><br><span class=\"line\">Metastore connection URL:\t jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=<span class=\"literal\">true</span></span><br><span class=\"line\">Metastore Connection Driver :\t com.mysql.jdbc.Driver</span><br><span class=\"line\">Metastore connection User:\t root</span><br><span class=\"line\">Starting metastore schema initialization to 1.2.0</span><br><span class=\"line\">Initialization script hive-schema-1.2.0.mysql.sql</span><br><span class=\"line\">Initialization script completed</span><br><span class=\"line\">schemaTool completed</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"启动hive\"><a class=\"anchor\" href=\"#启动hive\">#</a> 启动 Hive</h3>\n<p><figure class=\"highlight bash\"><figcaption><span>Bash命令</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master bin]<span class=\"comment\"># ./hive</span></span><br><span class=\"line\"></span><br><span class=\"line\">Logging initialized using configuration <span class=\"keyword\">in</span> jar:file:/<span class=\"built_in\">export</span>/servers/apache-hive-1.2.1-bin/lib/hive-common-1.2.1.jar!/hive-log4j.properties</span><br><span class=\"line\">hive&gt; show databases;</span><br><span class=\"line\">OK</span><br><span class=\"line\">default</span><br><span class=\"line\">Time taken: 0.901 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure><br />\n​\t到此为止，Hive 已经安装完成！！</p>\n",
            "tags": [
                "大数据技术与应用",
                "Hive"
            ]
        },
        {
            "id": "http://example.com/2020/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E5%90%AF%E5%8A%A8Hadoop%E9%9B%86%E7%BE%A4/",
            "url": "http://example.com/2020/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E5%90%AF%E5%8A%A8Hadoop%E9%9B%86%E7%BE%A4/",
            "title": "7.启动Hadoop并查看",
            "date_published": "2020-12-02T11:33:43.701Z",
            "content_html": "<h1 id=\"启动hadoop集群\"><a class=\"anchor\" href=\"#启动hadoop集群\">#</a> 启动 Hadoop 集群</h1>\n<ul>\n<li>（1）格式化 NameNode</li>\n</ul>\n<p><figure class=\"highlight bash\"><figcaption><span>格式化NameNode</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master bin]<span class=\"comment\"># ./hdfs namenode -format</span></span><br><span class=\"line\">20/11/23 06:00:53 INFO namenode.NameNode: STARTUP_MSG: </span><br><span class=\"line\">/************************************************************</span><br><span class=\"line\">STARTUP_MSG: Starting NameNode</span><br><span class=\"line\">STARTUP_MSG:   host = master/192.168.146.171</span><br><span class=\"line\">STARTUP_MSG:   args = [-format]</span><br><span class=\"line\">STARTUP_MSG:   version = 2.6.0</span><br><span class=\"line\">STARTUP_MSG:   classpath = /usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/etc/hadoop:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/contrib/capacity-scheduler/*.jar</span><br><span class=\"line\">STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1; compiled by <span class=\"string\">&#x27;jenkins&#x27;</span> on 2014-11-13T21:10Z</span><br><span class=\"line\">STARTUP_MSG:   java = 1.7.0_79</span><br><span class=\"line\">************************************************************/</span><br><span class=\"line\">20/11/23 06:00:53 INFO namenode.NameNode: registered UNIX signal handlers <span class=\"keyword\">for</span> [TERM, HUP, INT]</span><br><span class=\"line\">20/11/23 06:00:53 INFO namenode.NameNode: createNameNode [-format]</span><br><span class=\"line\">20/11/23 06:00:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class=\"keyword\">for</span> your platform... using builtin-java classes <span class=\"built_in\">where</span> applicable</span><br><span class=\"line\">Formatting using clusterid: CID-0ec7849e-7813-4339-8c98-141398b579f8</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: No KeyProvider found.</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: fsLock is fair:<span class=\"literal\">true</span></span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000</span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=<span class=\"literal\">true</span></span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is <span class=\"built_in\">set</span> to 000:00:00:00.000</span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.BlockManager: The block deletion will start around 2020 Nov 23 06:00:55</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: Computing capacity <span class=\"keyword\">for</span> map BlocksMap</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: VM <span class=\"built_in\">type</span>       = 64-bit</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: 2.0% max memory 966.7 MB = 19.3 MB</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: capacity      = 2^21 = 2097152 entries</span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=<span class=\"literal\">false</span></span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.BlockManager: defaultReplication         = 3</span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.BlockManager: maxReplication             = 512</span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.BlockManager: minReplication             = 1</span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2</span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = <span class=\"literal\">false</span></span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000</span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.BlockManager: encryptDataTransfer        = <span class=\"literal\">false</span></span><br><span class=\"line\">20/11/23 06:00:55 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: supergroup          = supergroup</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: isPermissionEnabled = <span class=\"literal\">true</span></span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: HA Enabled: <span class=\"literal\">false</span></span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: Append Enabled: <span class=\"literal\">true</span></span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: Computing capacity <span class=\"keyword\">for</span> map INodeMap</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: VM <span class=\"built_in\">type</span>       = 64-bit</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: 1.0% max memory 966.7 MB = 9.7 MB</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: capacity      = 2^20 = 1048576 entries</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.NameNode: Caching file names occuring more than 10 <span class=\"built_in\">times</span></span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: Computing capacity <span class=\"keyword\">for</span> map cachedBlocks</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: VM <span class=\"built_in\">type</span>       = 64-bit</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: 0.25% max memory 966.7 MB = 2.4 MB</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: capacity      = 2^18 = 262144 entries</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: Retry cache on namenode is enabled</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: Computing capacity <span class=\"keyword\">for</span> map NameNodeRetryCache</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: VM <span class=\"built_in\">type</span>       = 64-bit</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB</span><br><span class=\"line\">20/11/23 06:00:55 INFO util.GSet: capacity      = 2^15 = 32768 entries</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.NNConf: ACLs enabled? <span class=\"literal\">false</span></span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.NNConf: XAttrs enabled? <span class=\"literal\">true</span></span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.NNConf: Maximum size of an xattr: 16384</span><br><span class=\"line\">20/11/23 06:00:55 INFO namenode.FSImage: Allocated new BlockPoolId: BP-2023851825-192.168.146.171-1606082455765</span><br><span class=\"line\">20/11/23 06:00:55 INFO common.Storage: Storage directory /data/hadoop/hdfs/name has been successfully formatted.</span><br><span class=\"line\">20/11/23 06:00:56 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0</span><br><span class=\"line\">20/11/23 06:00:56 INFO util.ExitUtil: Exiting with status 0</span><br><span class=\"line\">20/11/23 06:00:56 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class=\"line\">/************************************************************</span><br><span class=\"line\">SHUTDOWN_MSG: Shutting down NameNode at master/192.168.146.171</span><br><span class=\"line\">************************************************************/</span><br><span class=\"line\">[root@master bin]<span class=\"comment\"># </span></span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>（2）启动集群</li>\n</ul>\n<p><figure class=\"highlight bash\"><figcaption><span>启动集群</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master bin]<span class=\"comment\"># cd /usr/local/hadoop-2.6.0/sbin</span></span><br><span class=\"line\">[root@master sbin]<span class=\"comment\"># ./start-dfs.sh</span></span><br><span class=\"line\">20/11/23 06:03:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class=\"keyword\">for</span> your platform... using builtin-java classes <span class=\"built_in\">where</span> applicable</span><br><span class=\"line\">Starting namenodes on [master]</span><br><span class=\"line\">master: starting namenode, logging to /usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/logs/hadoop-root-namenode-master.out</span><br><span class=\"line\">slave1: starting datanode, logging to /usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/logs/hadoop-root-datanode-slave1.out</span><br><span class=\"line\">slave2: starting datanode, logging to /usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/logs/hadoop-root-datanode-slave2.out</span><br><span class=\"line\">Starting secondary namenodes [master]</span><br><span class=\"line\">master: starting secondarynamenode, logging to /usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/logs/hadoop-root-secondarynamenode-master.out</span><br><span class=\"line\">20/11/23 06:03:51 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class=\"keyword\">for</span> your platform... using builtin-java classes <span class=\"built_in\">where</span> applicable</span><br><span class=\"line\">[root@master sbin]<span class=\"comment\"># ./start-yarn.sh</span></span><br><span class=\"line\">starting yarn daemons</span><br><span class=\"line\">starting resourcemanager, logging to /usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/logs/yarn-root-resourcemanager-master.out</span><br><span class=\"line\">slave1: starting nodemanager, logging to /usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/logs/yarn-root-nodemanager-slave1.out</span><br><span class=\"line\">slave2: starting nodemanager, logging to /usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/logs/yarn-root-nodemanager-slave2.out</span><br><span class=\"line\">[root@master sbin]<span class=\"comment\"># ./mr-jobhistory-daemon.sh start historyserver</span></span><br><span class=\"line\">starting historyserver, logging to /usr/<span class=\"built_in\">local</span>/hadoop-2.6.0/logs/mapred-root-historyserver-master.out</span><br><span class=\"line\">[root@master sbin]<span class=\"comment\"># jps</span></span><br><span class=\"line\">1744 NameNode</span><br><span class=\"line\">2049 ResourceManager</span><br><span class=\"line\">2322 JobHistoryServer</span><br><span class=\"line\">1915 SecondaryNameNode</span><br><span class=\"line\">2355 Jps</span><br><span class=\"line\">[root@master sbin]<span class=\"comment\"># </span></span><br></pre></td></tr></table></figure></p>\n<p>slave1 和 slave2 节点上的进程情况</p>\n<p><figure class=\"highlight bash\"><figcaption><span>节点jps显示情况</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@slave1 ~]<span class=\"comment\"># jps</span></span><br><span class=\"line\">1672 NodeManager</span><br><span class=\"line\">1792 Jps</span><br><span class=\"line\">1584 DataNode</span><br><span class=\"line\"></span><br><span class=\"line\">[root@slave2 ~]<span class=\"comment\"># jps</span></span><br><span class=\"line\">1582 DataNode</span><br><span class=\"line\">1670 NodeManager</span><br><span class=\"line\">1781 Jps</span><br></pre></td></tr></table></figure></p>\n<h1 id=\"浏览器查看启动页面\"><a class=\"anchor\" href=\"#浏览器查看启动页面\">#</a> 浏览器查看启动页面</h1>\n<ul>\n<li>(1) 在 Windows 下 C:\\Windows\\System32\\drivers\\etc\\hosts 添加 IP 映射</li>\n</ul>\n<p><figure class=\"highlight bash\"><figcaption><span>在windows上添加IP映射</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># localhost name resolution is handled within DNS itself.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#127.0.0.1       localhost</span></span><br><span class=\"line\"><span class=\"comment\">#::1             localhost</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 127.0.0.1       activate.navicat.com</span></span><br><span class=\"line\">192.168.146.171 master</span><br><span class=\"line\">192.168.146.172 slave1</span><br><span class=\"line\">192.168.136.173 slave2</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>\n<p>(2) 浏览器查看运行状态</p>\n<p>Hadoop 集群相关服务监控信息</p>\n<table>\n<thead>\n<tr>\n<th>服务</th>\n<th>Web 接口</th>\n<th>默认端口</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>NameNode</td>\n<td>http://namenode_host:port/</td>\n<td>50070</td>\n</tr>\n<tr>\n<td>ResourceManager</td>\n<td>http://resourcemanager_host:port/</td>\n<td>8088</td>\n</tr>\n<tr>\n<td>MapReduce JobHistory Server</td>\n<td>http://jobhistoryserver_host:port/</td>\n<td>19888</td>\n</tr>\n</tbody>\n</table>\n<p><strong>HDFS 监控</strong></p>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/22/DGJ9FH.jpg\" alt=\"DGJ9FH.jpg\" title=\"图7-2 hdfs监控\" /></p>\n<p><strong>YARN 监控</strong><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/22/DGJSTe.jpg\" alt=\"DGJSTe.jpg\" title=\"图7-3 yarn监控\" /></p>\n<p><strong>日志监控</strong><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/22/DGGzwD.jpg\" alt=\"DGGzwD.jpg\" title=\"图7-3 日志监控\" /></p>\n</li>\n</ul>\n<h1 id=\"关闭集群的顺序\"><a class=\"anchor\" href=\"#关闭集群的顺序\">#</a> 关闭集群的顺序</h1>\n<p><figure class=\"highlight bash\"><figcaption><span>关闭集群</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master sbin]<span class=\"comment\"># ./stop-yarn.sh</span></span><br><span class=\"line\">stopping yarn daemons</span><br><span class=\"line\">stopping resourcemanager</span><br><span class=\"line\">slave2: stopping nodemanager</span><br><span class=\"line\">slave1: stopping nodemanager</span><br><span class=\"line\">no proxyserver to stop</span><br><span class=\"line\">[root@master sbin]<span class=\"comment\"># ./stop-dfs.sh</span></span><br><span class=\"line\">20/11/23 06:36:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class=\"keyword\">for</span> your platform... using builtin-java classes <span class=\"built_in\">where</span> applicable</span><br><span class=\"line\">Stopping namenodes on [master]</span><br><span class=\"line\">master: stopping namenode</span><br><span class=\"line\">slave1: stopping datanode</span><br><span class=\"line\">slave2: stopping datanode</span><br><span class=\"line\">Stopping secondary namenodes [master]</span><br><span class=\"line\">master: stopping secondarynamenode</span><br><span class=\"line\">20/11/23 06:36:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class=\"keyword\">for</span> your platform... using builtin-java classes <span class=\"built_in\">where</span> applicable</span><br><span class=\"line\">[root@master sbin]<span class=\"comment\"># ./mr-jobhistory-daemon.sh stop historyserver</span></span><br><span class=\"line\">stopping historyserver</span><br><span class=\"line\">[root@master sbin]<span class=\"comment\"># </span></span><br></pre></td></tr></table></figure></p>\n",
            "tags": [
                "大数据技术与应用",
                "Hadoop"
            ]
        },
        {
            "id": "http://example.com/2020/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E9%85%8D%E7%BD%AE%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95/",
            "url": "http://example.com/2020/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E9%85%8D%E7%BD%AE%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95/",
            "title": "6.配置免密码登录",
            "date_published": "2020-12-02T11:33:42.425Z",
            "content_html": "<h1 id=\"配置免密码登录\"><a class=\"anchor\" href=\"#配置免密码登录\">#</a> 配置免密码登录</h1>\n<p>SSH (Secure Shell) 是建立在 TCP/IP 协议的应用层和传输层基础上的安全协议。SSH 保障了远程登录和网络传输服务的安全性，起到了防止信息泄露等作用。通过 SSH 可以对文件进行加密处理，SSH 也可以运行于多平台，配置 SSH 无密码登录的步骤如下。</p>\n<h2 id=\"配置ssh无密码登录\"><a class=\"anchor\" href=\"#配置ssh无密码登录\">#</a> 配置 SSH 无密码登录</h2>\n<ul>\n<li>（1）使用 ssh-keygen 产生公钥与私钥对，输入命令 “ssh-keygen -t rsa”，接着按三次 Enter 键。<br />\n<figure class=\"highlight bash\"><figcaption><span>使用ssh-keygen产生公钥与私钥对</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># ssh-keygen -t rsa</span></span><br><span class=\"line\">Generating public/private rsa key pair.</span><br><span class=\"line\">Enter file <span class=\"keyword\">in</span> <span class=\"built_in\">which</span> to save the key (/root/.ssh/id_rsa): </span><br><span class=\"line\">Created directory <span class=\"string\">&#x27;/root/.ssh&#x27;</span>.</span><br><span class=\"line\">Enter passphrase (empty <span class=\"keyword\">for</span> no passphrase): </span><br><span class=\"line\">Enter same passphrase again: </span><br><span class=\"line\">Your identification has been saved <span class=\"keyword\">in</span> /root/.ssh/id_rsa.</span><br><span class=\"line\">Your public key has been saved <span class=\"keyword\">in</span> /root/.ssh/id_rsa.pub.</span><br><span class=\"line\">The key fingerprint is:</span><br><span class=\"line\">20:dc:3e:20:db:26:64:a9:7f:aa:9f:b5:80:aa:ae:d3 root@master</span><br><span class=\"line\">The key<span class=\"string\">&#x27;s randomart image is:</span></span><br><span class=\"line\"><span class=\"string\">+--[ RSA 2048]----+</span></span><br><span class=\"line\"><span class=\"string\">|                 |</span></span><br><span class=\"line\"><span class=\"string\">|   o .           |</span></span><br><span class=\"line\"><span class=\"string\">|  = + o          |</span></span><br><span class=\"line\"><span class=\"string\">| + + + .         |</span></span><br><span class=\"line\"><span class=\"string\">|. o o o S        |</span></span><br><span class=\"line\"><span class=\"string\">| o o   .         |</span></span><br><span class=\"line\"><span class=\"string\">|..o o            |</span></span><br><span class=\"line\"><span class=\"string\">|o E* .           |</span></span><br><span class=\"line\"><span class=\"string\">|O=+ .            |</span></span><br><span class=\"line\"><span class=\"string\">+-----------------+</span></span><br></pre></td></tr></table></figure><br />\n 生成私有密钥 id_rsa 和公有密钥 id_rsa.pub 两个文件。ssh-keygen 用来生成 RSA 类型的密钥以及管理该密钥，参数 “-t” 用于指定要创建的 SSH 密钥的类型为 RSA。<br />\n（2）用 ssh-copy-id 将公钥复制到远程机器中<br />\n <figure class=\"highlight bash\"><figcaption><span>用ssh-copy-id将公钥复制到远程机器中</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># ssh-copy-id -i /root/.ssh/id_rsa.pub master</span></span><br><span class=\"line\">The authenticity of host <span class=\"string\">&#x27;master (192.168.146.171)&#x27;</span> can<span class=\"string\">&#x27;t be established.</span></span><br><span class=\"line\"><span class=\"string\">RSA key fingerprint is 55:83:9a:cb:34:60:b6:ce:0f:03:39:dd:e9:fc:99:c4.</span></span><br><span class=\"line\"><span class=\"string\">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class=\"line\"><span class=\"string\">Warning: Permanently added &#x27;</span>master,192.168.146.171<span class=\"string\">&#x27; (RSA) to the list of known hosts.</span></span><br><span class=\"line\"><span class=\"string\">root@master&#x27;</span>s password: </span><br><span class=\"line\">Now try logging into the machine, with <span class=\"string\">&quot;ssh &#x27;master&#x27;&quot;</span>, and check <span class=\"keyword\">in</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">  .ssh/authorized_keys</span><br><span class=\"line\"></span><br><span class=\"line\">to make sure we haven<span class=\"string\">&#x27;t added extra keys that you weren&#x27;</span>t expecting.</span><br><span class=\"line\"></span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># ssh-copy-id -i /root/.ssh/id_rsa.pub slave1</span></span><br><span class=\"line\">The authenticity of host <span class=\"string\">&#x27;slave1 (192.168.146.172)&#x27;</span> can<span class=\"string\">&#x27;t be established.</span></span><br><span class=\"line\"><span class=\"string\">RSA key fingerprint is 55:83:9a:cb:34:60:b6:ce:0f:03:39:dd:e9:fc:99:c4.</span></span><br><span class=\"line\"><span class=\"string\">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class=\"line\"><span class=\"string\">Warning: Permanently added &#x27;</span>slave1,192.168.146.172<span class=\"string\">&#x27; (RSA) to the list of known hosts.</span></span><br><span class=\"line\"><span class=\"string\">root@slave1&#x27;</span>s password: </span><br><span class=\"line\">Now try logging into the machine, with <span class=\"string\">&quot;ssh &#x27;slave1&#x27;&quot;</span>, and check <span class=\"keyword\">in</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">  .ssh/authorized_keys</span><br><span class=\"line\"></span><br><span class=\"line\">to make sure we haven<span class=\"string\">&#x27;t added extra keys that you weren&#x27;</span>t expecting.</span><br><span class=\"line\"></span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># ssh-copy-id -i /root/.ssh/id_rsa.pub slave2</span></span><br><span class=\"line\">The authenticity of host <span class=\"string\">&#x27;slave2 (192.168.146.173)&#x27;</span> can<span class=\"string\">&#x27;t be established.</span></span><br><span class=\"line\"><span class=\"string\">RSA key fingerprint is 55:83:9a:cb:34:60:b6:ce:0f:03:39:dd:e9:fc:99:c4.</span></span><br><span class=\"line\"><span class=\"string\">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class=\"line\"><span class=\"string\">Warning: Permanently added &#x27;</span>slave2,192.168.146.173<span class=\"string\">&#x27; (RSA) to the list of known hosts.</span></span><br><span class=\"line\"><span class=\"string\">root@slave2&#x27;</span>s password: </span><br><span class=\"line\">Now try logging into the machine, with <span class=\"string\">&quot;ssh &#x27;slave2&#x27;&quot;</span>, and check <span class=\"keyword\">in</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">  .ssh/authorized_keys</span><br><span class=\"line\"></span><br><span class=\"line\">to make sure we haven<span class=\"string\">&#x27;t added extra keys that you weren&#x27;</span>t expecting.</span><br><span class=\"line\"></span><br><span class=\"line\">[root@master ~]<span class=\"comment\">#</span></span><br></pre></td></tr></table></figure><br />\n（3）验证是否设置无密码登录，在 master 虚拟机上进行测试<br />\n <figure class=\"highlight bash\"><figcaption><span>验证是否设置无密码登录</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># ssh slave1</span></span><br><span class=\"line\">Last login: Mon Nov 23 00:58:04 2020 from 192.168.146.100</span><br><span class=\"line\">[root@slave1 ~]<span class=\"comment\"># exit   # 已经免密码登录slave1中，主机名已经发生变化</span></span><br><span class=\"line\"><span class=\"built_in\">logout</span></span><br><span class=\"line\">Connection to slave1 closed.</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># ssh slave2</span></span><br><span class=\"line\">Last login: Mon Nov 23 01:04:19 2020 from 192.168.146.100</span><br><span class=\"line\">[root@slave2 ~]<span class=\"comment\"># exit</span></span><br><span class=\"line\"><span class=\"built_in\">logout</span></span><br><span class=\"line\">Connection to slave2 closed.</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># </span></span><br></pre></td></tr></table></figure></li>\n</ul>\n",
            "tags": [
                "大数据技术与应用",
                "Hadoop"
            ]
        },
        {
            "id": "http://example.com/2020/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E5%85%8B%E9%9A%86%E8%8A%82%E7%82%B9%E9%85%8D%E7%BD%AE%E4%BF%AE%E6%94%B9/",
            "url": "http://example.com/2020/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E5%85%8B%E9%9A%86%E8%8A%82%E7%82%B9%E9%85%8D%E7%BD%AE%E4%BF%AE%E6%94%B9/",
            "title": "5.克隆节点配置修改",
            "date_published": "2020-12-02T11:33:40.669Z",
            "content_html": "<h1 id=\"克隆节点配置修改\"><a class=\"anchor\" href=\"#克隆节点配置修改\">#</a> 克隆节点配置修改</h1>\n<p>在虚拟机 master 上安装及配置完成之后，将虚拟机 master 克隆两台虚拟机，得到 slave1 和 slave2，总共三台虚拟机。但是克隆出来的虚拟机需要一定的配置和修改才能使用。</p>\n<h2 id=\"克隆master虚拟机\"><a class=\"anchor\" href=\"#克隆master虚拟机\">#</a> 克隆 master 虚拟机</h2>\n<p>在克隆 master 虚拟机之前需要将<strong> master 虚拟关机</strong>后才能使用克隆功能</p>\n<ul>\n<li>（1）右键单击虚拟机 master，选择 “<strong>管理</strong>”→“<strong>克隆</strong>” 命令，来到欢迎使用克隆虚拟机向导的界面，直接单击下一步，如图 5-1、5-2、5-3 所示</li>\n</ul>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/22/D8cISK.jpg\" alt=\"D8cISK.jpg\" title=\"图5-1 克隆\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/22/D8chJx.jpg\" alt=\"D8cISK.jpg\" title=\"图5-2 克隆欢迎界面\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/22/D8cRoR.jpg\" alt=\"D8cISK.jpg\" title=\"图5-3 克隆源\" /></p>\n<ul>\n<li>（2）选择 “<strong>创建完整克隆</strong>” 单击按钮并单击 “下一步” 按钮，如图 5-4 所示。</li>\n</ul>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/22/D8cfF1.jpg\" alt=\"D8cISK.jpg\" title=\"图5-4 克隆类型\" /></p>\n<ul>\n<li>（3）设置新虚拟机的名称，新虚拟机名称为 slave1，并选择安装位置，单击完成，虚拟机开始克隆，最后单击 “关闭” 按钮，克隆虚拟机完成，如图 5-5、5-6 所示。</li>\n</ul>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/22/D8cRoR.jpg\" alt=\"D8cISK.jpg\" title=\"图5-5 克隆源\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/22/D8c4W6.jpg\" alt=\"D8cISK.jpg\" title=\"图5-6 克隆完成\" /></p>\n<ul>\n<li>（4）重复 1-3 步骤可以得到 slave2 虚拟机。</li>\n</ul>\n<h2 id=\"克隆虚拟机配置\"><a class=\"anchor\" href=\"#克隆虚拟机配置\">#</a> 克隆虚拟机配置</h2>\n<p>克隆完成之后的虚拟机，slave1 和 slave2 都是不可以直接使用的，因为克隆的信息都是 master 的信息，需要修改之后才能使用，开启 slave1 虚拟机。</p>\n<p>（1）执行命令 “<strong>ifconfig -a</strong>”，查看 HWADDR，记录新虚拟机的网卡名和 HWADDR（不同的机器此值是不一样的），例如下面显示的<strong> eth1</strong> 和 HWaddr：00:0C:29:90:31:E2。</p>\n<p><figure class=\"highlight bash\"><figcaption><span>查看配置信息</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># ifconfig -a</span></span><br><span class=\"line\">eth1      Link encap:Ethernet  HWaddr 00:0C:29:90:31:E2  </span><br><span class=\"line\">          inet addr:192.168.146.172  Bcast:192.168.146.255  Mask:255.255.255.0</span><br><span class=\"line\">          inet6 addr: fe80::20c:29ff:fe90:31e2/64 Scope:Link</span><br><span class=\"line\">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class=\"line\">          RX packets:40 errors:0 dropped:0 overruns:0 frame:0</span><br><span class=\"line\">          TX packets:40 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class=\"line\">          collisions:0 txqueuelen:1000 </span><br><span class=\"line\">          RX bytes:4844 (4.7 KiB)  TX bytes:5039 (4.9 KiB)</span><br><span class=\"line\"></span><br><span class=\"line\">lo        Link encap:Local Loopback  </span><br><span class=\"line\">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class=\"line\">          inet6 addr: ::1/128 Scope:Host</span><br><span class=\"line\">          UP LOOPBACK RUNNING  MTU:16436  Metric:1</span><br><span class=\"line\">          RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class=\"line\">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class=\"line\">          collisions:0 txqueuelen:0 </span><br><span class=\"line\">          RX bytes:0 (0.0 b)  TX bytes:0 (0.0 b)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure><br />\n（3）修改 /etc/sysconfig/network-scripts/ifcfg-eth0 文件，修改 DEVICE、HWADDR 和 IPADDR，并 service network restart 重启网络服务。<br />\n<figure class=\"highlight bash\"><figcaption><span>修改slave1配置信息</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># vi /etc/sysconfig/network-scripts/ifcfg-eth0 </span></span><br><span class=\"line\">DEVICE=eth1   <span class=\"comment\">#修改成ifconfig -a显示的信息</span></span><br><span class=\"line\">HWADDR=00:0C:29:90:31:E2    <span class=\"comment\">#修改成ifconfig -a显示的信息</span></span><br><span class=\"line\">TYPE=Ethernet</span><br><span class=\"line\">UUID=f994c111-ad55-4c32-8178-6c6069d8818c</span><br><span class=\"line\">ONBOOT=yes</span><br><span class=\"line\">NM_CONTROLLED=yes</span><br><span class=\"line\">BOOTPROTO=static</span><br><span class=\"line\">IPADDR=192.168.146.172  <span class=\"comment\">#修改ip</span></span><br><span class=\"line\">NETMASK=255.255.255.0</span><br><span class=\"line\">GATEWAY=192.168.146.2</span><br><span class=\"line\">DNS1=192.168.146.2</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># service network restart</span></span><br><span class=\"line\">Shutting down interface eth0:                              [  OK  ]</span><br><span class=\"line\">Shutting down loopback interface:                          [  OK  ]</span><br><span class=\"line\">Bringing up loopback interface:                            [  OK  ]</span><br><span class=\"line\">Bringing up interface eth0:  Determining <span class=\"keyword\">if</span> ip address 192.168.146.172 is already <span class=\"keyword\">in</span> use <span class=\"keyword\">for</span> device eth1...</span><br><span class=\"line\">                                                           [  OK  ]</span><br></pre></td></tr></table></figure></p>\n<div class=\"note info\">\n<p>上述修改完成之后，同样的可以使用 xshell 连接 slave1 节点虚拟机。</p>\n</div>\n<p>（4）修改主机名，执行命令 “vi /etc/sysconfig/network”，修改的主机名为 “<strong>slave1</strong>”，重启机器，执行<strong> reboot</strong> 命令，验证 slave1 主机名是否配置成功。</p>\n<p><figure class=\"highlight bash\"><figcaption><span>主机名并测试</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># vi /etc/sysconfig/network</span></span><br><span class=\"line\">NETWORKING=yes</span><br><span class=\"line\">HOSTNAME=slave1  <span class=\"comment\"># 将master修改成mster，并保存退出</span></span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># reboot               #重新登录xshell</span></span><br><span class=\"line\">[root@slave1 ~]<span class=\"comment\">#                   # 主机名已经修改</span></span><br></pre></td></tr></table></figure></p>\n<p>（4）在 slave1 和 server2 中配置 NTP，同样修改 /etc/ntp.conf 文件，注释掉 server 开头的行，并添加:<br />\n<figure class=\"highlight bash\"><figcaption><span>修改/etc/ntp.conf文件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@slave1 ~]<span class=\"comment\"># vi /etc/ntp.conf</span></span><br><span class=\"line\"><span class=\"comment\"># the administrative functions.</span></span><br><span class=\"line\">restrict 127.0.0.1</span><br><span class=\"line\">restrict -6 ::1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Hosts on local network are less restricted.</span></span><br><span class=\"line\"><span class=\"comment\">#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use public servers from the pool.ntp.org project.</span></span><br><span class=\"line\"><span class=\"comment\"># Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class=\"line\"><span class=\"comment\">#server 0.centos.pool.ntp.org iburst</span></span><br><span class=\"line\"><span class=\"comment\">#server 1.centos.pool.ntp.org iburst</span></span><br><span class=\"line\"><span class=\"comment\">#server 2.centos.pool.ntp.org iburst</span></span><br><span class=\"line\"><span class=\"comment\">#server 3.centos.pool.ntp.org iburst</span></span><br><span class=\"line\">server master</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#broadcast 192.168.1.255 autokey        # broadcast server</span></span><br><span class=\"line\"><span class=\"comment\">#broadcastclient                        # broadcast client</span></span><br><span class=\"line\"><span class=\"comment\">#broadcast 224.0.1.1 autokey            # multicast server</span></span><br><span class=\"line\"><span class=\"comment\">#multicastclient 224.0.1.1              # multicast client</span></span><br><span class=\"line\"><span class=\"comment\">#manycastserver 239.255.254.254         # manycast server</span></span><br><span class=\"line\"><span class=\"comment\">#manycastclient 239.255.254.254 autokey # manycast client</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Enable public key cryptography.</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></p>\n<p>（5）启动 NTP 服务。<br />\n①  在 slave1 和 slave2 上执行命令 “ntpdate master” 即可同步时间。<br />\n②  在 slave1 和 slave2 上执行 “service ntpd start &amp; chkconfig ntpd on” 即可启动并永久启动。NTP 服务。</p>\n<p><figure class=\"highlight bash\"><figcaption><span>永久性关闭防火墙</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># ssh slave1</span></span><br><span class=\"line\">Last login: Mon Nov 23 02:18:41 2020 from 192.168.146.171</span><br><span class=\"line\">[root@slave1 ~]<span class=\"comment\"># ntpdate master</span></span><br><span class=\"line\">23 Nov 02:22:40 ntpdate[1396]: adjust time server 192.168.146.171 offset 0.488075 sec</span><br><span class=\"line\">[root@slave1 ~]<span class=\"comment\"># service ntpd start &amp; chkconfig ntpd on</span></span><br><span class=\"line\">[1] 1411</span><br><span class=\"line\">[root@slave1 ~]<span class=\"comment\"># Starting ntpd:                            [  OK  ]</span></span><br><span class=\"line\"></span><br><span class=\"line\">[1]+  Done                    service ntpd start</span><br><span class=\"line\">[root@slave1 ~]<span class=\"comment\"># exit</span></span><br><span class=\"line\"><span class=\"built_in\">logout</span></span><br><span class=\"line\">Connection to slave1 closed.</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># ssh slave2</span></span><br><span class=\"line\">Last login: Mon Nov 23 02:22:54 2020 from master</span><br><span class=\"line\">[root@slave2 ~]<span class=\"comment\"># ntpdate master</span></span><br><span class=\"line\">23 Nov 02:23:37 ntpdate[1329]: adjust time server 192.168.146.171 offset 0.497395 sec</span><br><span class=\"line\">[root@slave2 ~]<span class=\"comment\"># service ntpd start &amp; chkconfig ntpd on</span></span><br><span class=\"line\">[1] 1330</span><br><span class=\"line\">[root@slave2 ~]<span class=\"comment\"># Starting ntpd:                            [  OK  ]</span></span><br><span class=\"line\"></span><br><span class=\"line\">[1]+  Done                    service ntpd start</span><br><span class=\"line\">[root@slave2 ~]<span class=\"comment\"># exit</span></span><br><span class=\"line\"><span class=\"built_in\">logout</span></span><br><span class=\"line\">Connection to slave2 closed.</span><br><span class=\"line\">[root@master ~]<span class=\"comment\">#</span></span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>（6）查看个节点的时间：时间应该同步，非常接近</li>\n</ul>\n<p><figure class=\"highlight bash\"><figcaption><span>节点时间</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># date</span></span><br><span class=\"line\">Mon Nov 23 02:32:52 CST 2020</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># ssh slave1</span></span><br><span class=\"line\">Last login: Mon Nov 23 02:23:11 2020 from master</span><br><span class=\"line\">[root@slave1 ~]<span class=\"comment\"># date</span></span><br><span class=\"line\">Mon Nov 23 02:32:57 CST 2020</span><br><span class=\"line\">[root@slave1 ~]<span class=\"comment\"># exit</span></span><br><span class=\"line\"><span class=\"built_in\">logout</span></span><br><span class=\"line\">Connection to slave1 closed.</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># ssh slave2</span></span><br><span class=\"line\">Last login: Sun Nov 22 18:29:36 2020 from 192.168.146.100</span><br><span class=\"line\">[root@slave2 ~]<span class=\"comment\"># date</span></span><br><span class=\"line\">Mon Nov 23 02:33:05 CST 2020</span><br><span class=\"line\">[root@slave2 ~]<span class=\"comment\"># exit</span></span><br><span class=\"line\"><span class=\"built_in\">logout</span></span><br><span class=\"line\">Connection to slave2 closed.</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># </span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></p>\n",
            "tags": [
                "大数据技术与应用",
                "Hadoop"
            ]
        },
        {
            "id": "http://example.com/2020/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1%E3%80%81%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99%E3%80%81IP%E6%98%A0%E5%B0%84/",
            "url": "http://example.com/2020/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1%E3%80%81%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99%E3%80%81IP%E6%98%A0%E5%B0%84/",
            "title": "4.时间同步服务、关闭防火墙、IP映射",
            "date_published": "2020-12-02T11:33:10.615Z",
            "content_html": "<h1 id=\"时间同步服务-关闭防火墙-ip映射\"><a class=\"anchor\" href=\"#时间同步服务-关闭防火墙-ip映射\">#</a> 时间同步服务、关闭防火墙、IP 映射</h1>\n<p>NTP 是用来使计算机时间同步化的一种协议，它可以使计算机对其服务器或时钟源做同步化，提供高精准度的时间校正。Hadoop 集群对时间要求很高，主节点与各从节点的时间都必须要同步。配置时间同步服务主要是为了进行集群间的时间同步。Hadoop 集群配置时间同步服务的步骤如下：</p>\n<p>方式一：在线安装 ntp 服务，在 master 节点安装 NTP 服务。</p>\n<ul>\n<li>（1）不换任何下载源的情况下，在 master 节点安装 NTP 服务</li>\n</ul>\n<p><figure class=\"highlight bash\"><figcaption><span>安装NTP服务</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># yum -y install ntp</span></span><br><span class=\"line\">Loaded plugins: fastestmirror</span><br><span class=\"line\">Loading mirror speeds from cached hostfile</span><br><span class=\"line\">Setting up Install Process</span><br><span class=\"line\">Resolving Dependencies</span><br><span class=\"line\">--&gt; Running transaction check</span><br><span class=\"line\">---&gt; Package ntp.x86_64 0:4.2.6p5-15.el6.centos will be installed</span><br><span class=\"line\">--&gt; Processing Dependency: ntpdate = 4.2.6p5-15.el6.centos <span class=\"keyword\">for</span> package: ntp-4.2.6p5-15.el6.centos.x86_64</span><br><span class=\"line\">--&gt; Running transaction check</span><br><span class=\"line\">---&gt; Package ntpdate.x86_64 0:4.2.6p5-15.el6.centos will be installed</span><br><span class=\"line\">--&gt; Finished Dependency Resolution</span><br><span class=\"line\"></span><br><span class=\"line\">Dependencies Resolved</span><br><span class=\"line\"></span><br><span class=\"line\">========================================================================================</span><br><span class=\"line\"> Package          Arch            Version                        Repository        Size</span><br><span class=\"line\">========================================================================================</span><br><span class=\"line\">Installing:</span><br><span class=\"line\"> ntp              x86_64          4.2.6p5-15.el6.centos          updates          600 k</span><br><span class=\"line\">Installing <span class=\"keyword\">for</span> dependencies:</span><br><span class=\"line\"> ntpdate          x86_64          4.2.6p5-15.el6.centos          updates           79 k</span><br><span class=\"line\"></span><br><span class=\"line\">Transaction Summary</span><br><span class=\"line\">========================================================================================</span><br><span class=\"line\">Install       2 Package(s)</span><br><span class=\"line\"></span><br><span class=\"line\">Total download size: 679 k</span><br><span class=\"line\">Installed size: 1.8 M</span><br><span class=\"line\">Downloading Packages:</span><br><span class=\"line\">(1/2): ntp-4.2.6p5-15.el6.centos.x86_64.rpm                      | 600 kB     03:13     </span><br><span class=\"line\">(2/2): ntpdate-4.2.6p5-15.el6.centos.x86_64.rpm                  |  79 kB     00:04     </span><br><span class=\"line\">----------------------------------------------------------------------------------------</span><br><span class=\"line\">Total                                                   3.4 kB/s | 679 kB     03:19     </span><br><span class=\"line\">warning: rpmts_HdrFromFdno: Header V3 RSA/SHA1 Signature, key ID c105b9de: NOKEY</span><br><span class=\"line\">Retrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6</span><br><span class=\"line\">Importing GPG key 0xC105B9DE:</span><br><span class=\"line\"> Userid : CentOS-6 Key (CentOS 6 Official Signing Key) &lt;centos-6-key@centos.org&gt;</span><br><span class=\"line\"> Package: centos-release-6-5.el6.centos.11.1.x86_64 (@anaconda-CentOS-201311272149.x86_64/6.5)</span><br><span class=\"line\"> From   : /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6</span><br><span class=\"line\">Running rpm_check_debug</span><br><span class=\"line\">Running Transaction Test</span><br><span class=\"line\">Transaction Test Succeeded</span><br><span class=\"line\">Running Transaction</span><br><span class=\"line\">  Installing : ntpdate-4.2.6p5-15.el6.centos.x86_64                                 1/2 </span><br><span class=\"line\">  Installing : ntp-4.2.6p5-15.el6.centos.x86_64                                     2/2 </span><br><span class=\"line\">  Verifying  : ntpdate-4.2.6p5-15.el6.centos.x86_64                                 1/2 </span><br><span class=\"line\">  Verifying  : ntp-4.2.6p5-15.el6.centos.x86_64                                     2/2 </span><br><span class=\"line\"></span><br><span class=\"line\">Installed:</span><br><span class=\"line\">  ntp.x86_64 0:4.2.6p5-15.el6.centos                                                    </span><br><span class=\"line\"></span><br><span class=\"line\">Dependency Installed:</span><br><span class=\"line\">  ntpdate.x86_64 0:4.2.6p5-15.el6.centos                                                </span><br><span class=\"line\"></span><br><span class=\"line\">Complete!</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># </span></span><br></pre></td></tr></table></figure><br />\n<strong> 注意：不换镜像源，在线安装 ntp 服务很容易出现错误</strong></p>\n<ul>\n<li>切换下载源的情况下，在 master 节点安装 NTP 服务（推荐），操作流程如下：</li>\n</ul>\n<p><figure class=\"highlight text\"><figcaption><span>ntp服务安装</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">1、安装wget软件</span><br><span class=\"line\">yum install -y wget</span><br><span class=\"line\"></span><br><span class=\"line\">2、备份</span><br><span class=\"line\">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><br><span class=\"line\"></span><br><span class=\"line\">3、下载新的 CentOS-Base.repo 到 /etc/yum.repos.d/</span><br><span class=\"line\">CentOS 5</span><br><span class=\"line\">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo</span><br><span class=\"line\"></span><br><span class=\"line\">CentOS 6</span><br><span class=\"line\">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo</span><br><span class=\"line\"></span><br><span class=\"line\">CentOS 7</span><br><span class=\"line\">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class=\"line\"></span><br><span class=\"line\">4、之后运行yum makecache生成缓存</span><br></pre></td></tr></table></figure></p>\n<p>方式二：离线安装 ntp 服务</p>\n<ul>\n<li>（1）使用 xshell 软件上传 ntp 两个离线安装包到 /opt 目录下，先输入 “<strong>rpm -ivh ntpdate-4.2.6p5-12.el6.centos.2.x86_64.rpm</strong>” 安装，然后输入 “<strong>rpm -ivh ntp-4.2.6p5-12.el6.centos.2.x86_64.rpm</strong>”</li>\n</ul>\n<p><figure class=\"highlight bash\"><figcaption><span>离线安装ntp软件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master opt]<span class=\"comment\"># ll</span></span><br><span class=\"line\">total 341828</span><br><span class=\"line\">-rw-r--r--. 1 root root 195257604 Dec  1 04:21 hadoop-2.6.0.tar_4.gz</span><br><span class=\"line\">-rw-r--r--. 1 root root 153512879 Dec  1 04:21 jdk-7u79-linux-x64.tar.gz</span><br><span class=\"line\">-rw-r--r--. 1 root root    614088 Dec  1 05:20 ntp-4.2.6p5-12.el6.centos.2.x86_64.rpm</span><br><span class=\"line\">-rw-r--r--. 1 root root     80736 Dec  1 05:20 ntpdate-4.2.6p5-12.el6.centos.2.x86_64.rpm</span><br><span class=\"line\">-rw-r--r--. 1 root root    560272 Dec  1 11:21 wget-1.14-18.el7_6.1.x86_64.rpm</span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># rpm -ivh ntpdate-4.2.6p5-12.el6.centos.2.x86_64.rpm </span></span><br><span class=\"line\">warning: ntpdate-4.2.6p5-12.el6.centos.2.x86_64.rpm: Header V3 RSA/SHA1 Signature, key ID c105b9de: NOKEY</span><br><span class=\"line\">Preparing...                <span class=\"comment\">########################################### [100%]</span></span><br><span class=\"line\">\tpackage ntpdate-4.2.6p5-12.el6.centos.2.x86_64 is already installed</span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># rpm -ivh ntp-4.2.6p5-12.el6.centos.2.x86_64.rpm </span></span><br><span class=\"line\">warning: ntp-4.2.6p5-12.el6.centos.2.x86_64.rpm: Header V3 RSA/SHA1 Signature, key ID c105b9de: NOKEY</span><br><span class=\"line\">Preparing...                <span class=\"comment\">########################################### [100%]</span></span><br><span class=\"line\">\tpackage ntp-4.2.6p5-12.el6.centos.2.x86_64 is already installed</span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># vi /etc/ntp.conf </span></span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># </span></span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>（2）设置 master 节点为 NTP 服务主节点，那么其配置如下。<br />\n使用命令 “vi /etc/ntp.conf” 打开 /etc/ntp.conf 文件，注释掉以 server 开头的行，并添加:<br />\n<figure class=\"highlight bash\"><figcaption><span>添加的信息</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">restrict 192.168.128.2 mask 255.255.255.0 nomodify notrap</span><br><span class=\"line\">server 127.127.1.0</span><br><span class=\"line\">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure></li>\n</ul>\n<p><figure class=\"highlight bash\"><figcaption><span>/etc/ntp.conf文件信息</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Permit all access over the loopback interface.  This could</span></span><br><span class=\"line\"><span class=\"comment\"># be tightened as well, but to do so would effect some of</span></span><br><span class=\"line\"><span class=\"comment\"># the administrative functions.</span></span><br><span class=\"line\">restrict 127.0.0.1</span><br><span class=\"line\">restrict -6 ::1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Hosts on local network are less restricted.</span></span><br><span class=\"line\"><span class=\"comment\">#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use public servers from the pool.ntp.org project.</span></span><br><span class=\"line\"><span class=\"comment\"># Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class=\"line\">server 0.centos.pool.ntp.org iburst</span><br><span class=\"line\">server 1.centos.pool.ntp.org iburst</span><br><span class=\"line\">server 2.centos.pool.ntp.org iburst</span><br><span class=\"line\">server 3.centos.pool.ntp.org iburst</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#broadcast 192.168.1.255 autokey        # broadcast server</span></span><br><span class=\"line\"><span class=\"comment\">#broadcastclient                        # broadcast client</span></span><br><span class=\"line\"><span class=\"comment\">#broadcast 224.0.1.1 autokey            # multicast server</span></span><br><span class=\"line\"><span class=\"comment\">#multicastclient 224.0.1.1              # multicast client</span></span><br><span class=\"line\"><span class=\"comment\">#manycastserver 239.255.254.254         # manycast server</span></span><br><span class=\"line\"><span class=\"comment\">#manycastclient 239.255.254.254 autokey # manycast client</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Enable public key cryptography.</span></span><br><span class=\"line\"><span class=\"comment\">#crypto</span></span><br></pre></td></tr></table></figure></p>\n<p><figure class=\"highlight bash\"><figcaption><span>修改后的/etc/ntp.conf文件信息</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Permit all access over the loopback interface.  This could</span></span><br><span class=\"line\"><span class=\"comment\"># be tightened as well, but to do so would effect some of</span></span><br><span class=\"line\"><span class=\"comment\"># the administrative functions.</span></span><br><span class=\"line\">restrict 127.0.0.1</span><br><span class=\"line\">restrict -6 ::1</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Hosts on local network are less restricted.</span></span><br><span class=\"line\"><span class=\"comment\">#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Use public servers from the pool.ntp.org project.</span></span><br><span class=\"line\"><span class=\"comment\"># Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class=\"line\"><span class=\"comment\">#server 0.centos.pool.ntp.org iburst</span></span><br><span class=\"line\"><span class=\"comment\">#server 1.centos.pool.ntp.org iburst</span></span><br><span class=\"line\"><span class=\"comment\">#server 2.centos.pool.ntp.org iburst</span></span><br><span class=\"line\"><span class=\"comment\">#server 3.centos.pool.ntp.org iburst</span></span><br><span class=\"line\">restrict 192.168.146.2 mask 255.255.255.0 nomodify notrap  <span class=\"comment\"># 修改对应的ip地址</span></span><br><span class=\"line\">  server 127.127.1.0</span><br><span class=\"line\">  fudge 127.127.1.0 stratum 10</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#broadcast 192.168.1.255 autokey        # broadcast server</span></span><br><span class=\"line\"><span class=\"comment\">#broadcastclient                        # broadcast client</span></span><br><span class=\"line\"><span class=\"comment\">#broadcast 224.0.1.1 autokey            # multicast server</span></span><br><span class=\"line\"><span class=\"comment\">#multicastclient 224.0.1.1              # multicast client</span></span><br><span class=\"line\"><span class=\"comment\">#manycastserver 239.255.254.254         # manycast server</span></span><br><span class=\"line\"><span class=\"comment\">#manycastclient 239.255.254.254 autokey # manycast client</span></span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>\n<p>（3）关闭防火墙<br />\n状执行命令 “service iptables stop &amp; chkconfig iptables off” 永久性关闭防火墙，&quot;service iptables status&quot; 查看关闭状态。<br />\n<figure class=\"highlight text\"><figcaption><span>关闭防火墙</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# service iptables stop &amp; chkconfig iptables off</span><br><span class=\"line\">[1] 1268</span><br><span class=\"line\">[root@master ~]# iptables: Setting chains to policy ACCEPT:[  OK  ]</span><br><span class=\"line\">iptables: Flushing firewall rules:                         [  OK  ]</span><br><span class=\"line\">iptables: Unloading modules:                               [  OK  ]</span><br><span class=\"line\"></span><br><span class=\"line\">[1]+  Done                    service iptables stop  #如果关闭卡住，按一下回车键</span><br><span class=\"line\">[root@master ~]# service iptables status</span><br><span class=\"line\">iptables: Firewall is not running.</span><br><span class=\"line\">[1]+  Done                    service iptables stop</span><br><span class=\"line\">[root@master ~]#</span><br></pre></td></tr></table></figure></p>\n</li>\n<li>\n<p>(4) 在 master 配置 IP 映射，在 vi /etc/hosts 添加<br />\n 192.168.128.130 master  # 自己的 ip<br />\n192.168.128.131 slave1<br />\n192.168.128.132 slave2</p>\n</li>\n</ul>\n<p><figure class=\"highlight text\"><figcaption><span>配置ip映射</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]# vi /etc/hosts</span><br><span class=\"line\">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class=\"line\">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class=\"line\">192.168.146.171 master  #配置的ip 对应的主机名 ip存在不一样需要修改</span><br><span class=\"line\">192.168.146.172 slave1</span><br><span class=\"line\">192.168.146.173 slave2</span><br></pre></td></tr></table></figure></p>\n",
            "tags": [
                "大数据技术与应用",
                "Hadoop"
            ]
        },
        {
            "id": "http://example.com/2020/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E5%AE%89%E8%A3%85JDK%E5%8F%8AHadoop/",
            "url": "http://example.com/2020/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E5%AE%89%E8%A3%85JDK%E5%8F%8AHadoop/",
            "title": "3.安装Jdk及Hadoop",
            "date_published": "2020-12-02T11:32:25.816Z",
            "content_html": "<h1 id=\"安装jdk及hadoop\"><a class=\"anchor\" href=\"#安装jdk及hadoop\">#</a> 安装 Jdk 及 Hadoop</h1>\n<p>在 Linux 下安装 JDK 的步骤如下。</p>\n<ul>\n<li>（1）用 Xshell 软件的 Xft 将 JDK 安装包到上传到虚拟机 master，按 “Ctrl+Alt+F” 组合键，弹出文件传输框，把 jdk-7u79-linux-x64.tar.gz 上传到 /opt 目录下，如图 3-1 所示。</li>\n</ul>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/22/DGQFSK.jpg\" alt=\"DGQFSK.jpg\" title=\"图3-1 jdk和hadoop软件上传\" /></p>\n<ul>\n<li>（2）进入 /usr 目录，建立文件夹 java，进入 /opt 目录，执行命令 “<strong>tar -zxvf  jdk-7u79-linux-x64.tar.gz -C /usr/java</strong>”，解压文件到 /usr/java 文件夹。<br />\n<figure class=\"highlight bash\"><figcaption><span>解压jdk软件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># cd /opt/</span></span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># ll</span></span><br><span class=\"line\">total 149916</span><br><span class=\"line\">-rw-r--r--. 1 root root 153512879 Nov 23 02:47 jdk-7u79-linux-x64.tar.gz</span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># cd /usr/</span></span><br><span class=\"line\">[root@master usr]<span class=\"comment\"># ll</span></span><br><span class=\"line\">total 64</span><br><span class=\"line\">dr-xr-xr-x.  2 root root 12288 Nov 23 01:44 bin</span><br><span class=\"line\">drwxr-xr-x.  2 root root  4096 Sep 23  2011 etc</span><br><span class=\"line\">drwxr-xr-x.  2 root root  4096 Sep 23  2011 games</span><br><span class=\"line\">drwxr-xr-x.  3 root root  4096 Nov 20 01:57 include</span><br><span class=\"line\">dr-xr-xr-x.  9 root root  4096 Nov 20 01:57 lib</span><br><span class=\"line\">dr-xr-xr-x. 24 root root 12288 Nov 20 01:58 lib64</span><br><span class=\"line\">drwxr-xr-x.  9 root root  4096 Nov 20 01:58 libexec</span><br><span class=\"line\">drwxr-xr-x. 12 root root  4096 Nov 20 01:56 <span class=\"built_in\">local</span></span><br><span class=\"line\">dr-xr-xr-x.  2 root root  4096 Nov 23 01:44 sbin</span><br><span class=\"line\">drwxr-xr-x. 61 root root  4096 Nov 20 01:58 share</span><br><span class=\"line\">drwxr-xr-x.  4 root root  4096 Nov 20 01:56 src</span><br><span class=\"line\">lrwxrwxrwx.  1 root root    10 Nov 20 01:56 tmp -&gt; ../var/tmp</span><br><span class=\"line\">[root@master usr]<span class=\"comment\"># mkdir java</span></span><br><span class=\"line\">[root@master usr]<span class=\"comment\"># cd /opt/</span></span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># tar -zxvf jdk-7u79-linux-x64.tar.gz -C /usr/java/</span></span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># cd /usr/</span></span><br><span class=\"line\">[root@master usr]<span class=\"comment\"># cd java/</span></span><br><span class=\"line\">[root@master java]<span class=\"comment\"># ll</span></span><br><span class=\"line\">total 4</span><br><span class=\"line\">drwxr-xr-x. 8 uucp 143 4096 Apr 11  2015 jdk1.7.0_79</span><br></pre></td></tr></table></figure></li>\n<li>（3）在 /etc/profile 添加<br />\n <figure class=\"highlight bash\"><figcaption><span>修改/etc/profile设置</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/java/jdk1.7.0_79</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure><br />\n 并执行 source /etc/profile 使配置生效<br />\n <figure class=\"highlight bash\"><figcaption><span>修改/etc/profile设置</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master java]<span class=\"comment\"># vi /etc/profile</span></span><br><span class=\"line\"><span class=\"comment\"># /usr/share/doc/setup-*/uidgid file</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> [ <span class=\"variable\">$UID</span> -gt 199 ] &amp;&amp; [ <span class=\"string\">&quot;`id -gn`&quot;</span> = <span class=\"string\">&quot;`id -un`&quot;</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">    <span class=\"built_in\">umask</span> 002</span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">    <span class=\"built_in\">umask</span> 022</span><br><span class=\"line\"><span class=\"keyword\">fi</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> /etc/profile.d/*.sh ; <span class=\"keyword\">do</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> [ -r <span class=\"string\">&quot;<span class=\"variable\">$i</span>&quot;</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> [ <span class=\"string\">&quot;<span class=\"variable\">$&#123;-#*i&#125;</span>&quot;</span> != <span class=\"string\">&quot;$-&quot;</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">            . <span class=\"string\">&quot;<span class=\"variable\">$i</span>&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            . <span class=\"string\">&quot;<span class=\"variable\">$i</span>&quot;</span> &gt;/dev/null 2&gt;&amp;1</span><br><span class=\"line\">        <span class=\"keyword\">fi</span></span><br><span class=\"line\">    <span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">unset</span> i</span><br><span class=\"line\"><span class=\"built_in\">unset</span> -f pathmunge</span><br><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/java/jdk1.7.0_79</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</span><br><span class=\"line\">[root@master java]<span class=\"comment\"># source /etc/profile  # 使配置文件生效</span></span><br><span class=\"line\">[root@master java]<span class=\"comment\"># java -version  # 测试java安装成功</span></span><br><span class=\"line\">java version <span class=\"string\">&quot;1.7.0_79&quot;</span></span><br><span class=\"line\">Java(TM) SE Runtime Environment (build 1.7.0_79-b15)</span><br><span class=\"line\">Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)</span><br><span class=\"line\">[root@master java]<span class=\"comment\"># </span></span><br></pre></td></tr></table></figure></li>\n</ul>\n<h1 id=\"安装hadoop\"><a class=\"anchor\" href=\"#安装hadoop\">#</a> 安装 Hadoop</h1>\n<p>（1）进入 /usr 目录，建立文件夹 hadoop，进入 /opt 目录，执行命令 “<strong>tar -zxvf  jdk-7u79-linux-x64.tar.gz -C /usr/java</strong>”，解压文件到 /usr/java 文件夹。</p>\n<p><figure class=\"highlight bash\"><figcaption><span>安装hadoop文件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># cd /opt/</span></span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># ll</span></span><br><span class=\"line\">total 341280</span><br><span class=\"line\">-rw-r--r--. 1 root root 195257604 Dec  1 04:21 hadoop-2.6.0.tar_4.gz</span><br><span class=\"line\">-rw-r--r--. 1 root root 153512879 Dec  1 04:21 jdk-7u79-linux-x64.tar.gz</span><br><span class=\"line\">-rw-r--r--. 1 root root    614088 Dec  1 05:20 ntp-4.2.6p5-12.el6.centos.2.x86_64.rpm</span><br><span class=\"line\">-rw-r--r--. 1 root root     80736 Dec  1 05:20 ntpdate-4.2.6p5-12.el6.centos.2.x86_64.rpm</span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># mkdir /usr/hadoop/</span></span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># tar -zxvf hadoop-2.6.0.tar_4.gz -C /usr/hadoop</span></span><br><span class=\"line\">[root@master opt]<span class=\"comment\"># cd /usr/hadoop/hadoop-2.6.0/</span></span><br><span class=\"line\">[root@master hadoop-2.6.0]<span class=\"comment\"># ll</span></span><br><span class=\"line\">total 56</span><br><span class=\"line\">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 bin</span><br><span class=\"line\">drwxr-xr-x. 3 20000 20000  4096 Nov 14  2014 etc</span><br><span class=\"line\">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 include</span><br><span class=\"line\">drwxr-xr-x. 3 20000 20000  4096 Nov 14  2014 lib</span><br><span class=\"line\">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 libexec</span><br><span class=\"line\">-rw-r--r--. 1 20000 20000 15429 Nov 14  2014 LICENSE.txt</span><br><span class=\"line\">drwxr-xr-x. 2 root  root   4096 Dec  1 06:05 logs</span><br><span class=\"line\">-rw-r--r--. 1 20000 20000   101 Nov 14  2014 NOTICE.txt</span><br><span class=\"line\">-rw-r--r--. 1 20000 20000  1366 Nov 14  2014 README.txt</span><br><span class=\"line\">drwxr-xr-x. 2 20000 20000  4096 Nov 14  2014 sbin</span><br><span class=\"line\">drwxr-xr-x. 4 20000 20000  4096 Nov 14  2014 share</span><br><span class=\"line\">[root@master hadoop-2.6.0]<span class=\"comment\"># </span></span><br></pre></td></tr></table></figure></p>\n<p>（2) 修改 /etc/profile 文件，并配置环境变量，并测试 hadoop 是否成功安装<br />\n <figure class=\"highlight bash\"><figcaption><span>hadoop环境变量配置</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># vi /etc/profile</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> /etc/profile.d/*.sh ; <span class=\"keyword\">do</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> [ -r <span class=\"string\">&quot;<span class=\"variable\">$i</span>&quot;</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> [ <span class=\"string\">&quot;<span class=\"variable\">$&#123;-#*i&#125;</span>&quot;</span> != <span class=\"string\">&quot;$-&quot;</span> ]; <span class=\"keyword\">then</span></span><br><span class=\"line\">            . <span class=\"string\">&quot;<span class=\"variable\">$i</span>&quot;</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span></span><br><span class=\"line\">            . <span class=\"string\">&quot;<span class=\"variable\">$i</span>&quot;</span> &gt;/dev/null 2&gt;&amp;1</span><br><span class=\"line\">        <span class=\"keyword\">fi</span></span><br><span class=\"line\">    <span class=\"keyword\">fi</span></span><br><span class=\"line\"><span class=\"keyword\">done</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">unset</span> i</span><br><span class=\"line\"><span class=\"built_in\">unset</span> -f pathmunge</span><br><span class=\"line\"><span class=\"built_in\">export</span> JAVA_HOME=/usr/java/jdk1.7.0_79</span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$JAVA_HOME</span>/bin</span><br><span class=\"line\"><span class=\"built_in\">export</span> HADOOP_HOME=/usr/hadoop/hadoop-2.6.0  <span class=\"comment\"># 添加hadoop路径</span></span><br><span class=\"line\"><span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$HADOOP_HOME</span>/bin</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># source /etc/profile</span></span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># hadoop version</span></span><br><span class=\"line\">Hadoop 2.6.0</span><br><span class=\"line\">Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1</span><br><span class=\"line\">Compiled by jenkins on 2014-11-13T21:10Z</span><br><span class=\"line\">Compiled with protoc 2.5.0</span><br><span class=\"line\">From <span class=\"built_in\">source</span> with checksum 18e43357c8f927c0695f1e9522859d6a</span><br><span class=\"line\">This <span class=\"built_in\">command</span> was run using /usr/hadoop/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># </span></span><br></pre></td></tr></table></figure></p>\n<p>（3）修改 hadoop 配置文件，需要需改的配置文件（<strong>/hadoop 安装目录 /etc/hadoop</strong>），如下表格所示。</p>\n<ul>\n<li>1.hadoop-env.sh 配置文件</li>\n<li>2.yarn-env.sh 配置文件</li>\n<li>3.core.site.xml 配置文件</li>\n<li>4.hdfs-site.xml 配置文件</li>\n<li>5.mapred-site.xml 配置文件</li>\n<li>6.yarn-site.xml 配置文件</li>\n<li>7.slaves 配置文件</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th>配置文件名</th>\n<th>功能描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1</td>\n<td><span class=\"exturl\" data-url=\"aHR0cDovL2hhZG9vcC1lbnYuc2g=\">hadoop-env.sh</span></td>\n<td>配置 Hadoop 运行所需要的环境变量。</td>\n</tr>\n<tr>\n<td>2</td>\n<td><span class=\"exturl\" data-url=\"aHR0cDovL3lhcm4tZW52LnNo\">yarn-env.sh</span></td>\n<td>配置 YARN 运行所需的环境变量。</td>\n</tr>\n<tr>\n<td>3</td>\n<td>core.site.xml</td>\n<td>集群全局参数，用于定义系统级别的参数，如 HDFS URL、Hadoop 的临时目录等。</td>\n</tr>\n<tr>\n<td>4</td>\n<td>hdfs-site.xml</td>\n<td>HDFS 参数，如名称节点和数据节点的存放位置、文件副本的个数、文件读取的权限等。</td>\n</tr>\n<tr>\n<td>5</td>\n<td>mapred-site.xml</td>\n<td>MapReduce 参数，包括 Job History Server 和应用程序参数两部分，如 reduce 任务的默认个数、任务所能够使用内存的默认上下限等</td>\n</tr>\n<tr>\n<td>6</td>\n<td>yarn-site.xml</td>\n<td>集群资源管理系统参数，配置 ReourceManager、NodeManager 的通信端口，Web 监控端口等。</td>\n</tr>\n<tr>\n<td>7</td>\n<td>slave</td>\n<td>Hadoop 集群所有从节点主机名</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cDovL2hhZG9vcC1lbnYuc2g=\">hadoop-env.sh</span>：配置 Java 安装路径</li>\n</ul>\n<p><figure class=\"highlight text\"><figcaption><span>hadoop-env.sh配置文件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master hadoop]# vi hadoop-env.sh</span><br><span class=\"line\"># The only required environment variable is JAVA_HOME.  All others are</span><br><span class=\"line\"># optional.  When running a distributed configuration it is best to</span><br><span class=\"line\"># set JAVA_HOME in this file, so that it is correctly defined on</span><br><span class=\"line\"># remote nodes.</span><br><span class=\"line\"></span><br><span class=\"line\"># The java implementation to use.</span><br><span class=\"line\">export JAVA_HOME=/usr/java/jdk1.7.0_79  #修改的信息</span><br><span class=\"line\"></span><br><span class=\"line\"># The jsvc implementation to use. Jsvc is required to run secure datanodes</span><br><span class=\"line\"># that bind to privileged ports to provide authentication of data transfer</span><br><span class=\"line\"># protocol.  Jsvc is not required if SASL is configured for authentication of</span><br><span class=\"line\"># data transfer protocol using non-privileged ports.</span><br><span class=\"line\">#export JSVC_HOME=$&#123;JSVC_HOME&#125;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li><span class=\"exturl\" data-url=\"aHR0cDovL3lhcm4tZW52LnNo\">yarn-env.sh</span>：配置 Java 安装路径</li>\n</ul>\n<p><figure class=\"highlight text\"><figcaption><span>yarn-env.sh配置文件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master hadoop]# vi yarn-env.sh</span><br><span class=\"line\"># User for YARN daemons</span><br><span class=\"line\">export HADOOP_YARN_USER=$&#123;HADOOP_YARN_USER:-yarn&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"># resolve links - $0 may be a softlink</span><br><span class=\"line\">export YARN_CONF_DIR=&quot;$&#123;YARN_CONF_DIR:-$HADOOP_YARN_HOME/conf&#125;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># some Java parameters</span><br><span class=\"line\">export JAVA_HOME=/usr/java/jdk1.7.0_79 # 修改的内容</span><br><span class=\"line\">if [ &quot;$JAVA_HOME&quot; != &quot;&quot; ]; then</span><br><span class=\"line\">  #echo &quot;run java in $JAVA_HOME&quot;</span><br><span class=\"line\">  JAVA_HOME=$JAVA_HOME</span><br><span class=\"line\">fi</span><br><span class=\"line\"></span><br><span class=\"line\">if [ &quot;$JAVA_HOME&quot; = &quot;&quot; ]; then</span><br><span class=\"line\">  echo &quot;Error: JAVA_HOME is not set.&quot;</span><br><span class=\"line\">  exit 1</span><br><span class=\"line\">fi</span><br><span class=\"line\"></span><br><span class=\"line\">JAVA=$JAVA_HOME/bin/java</span><br><span class=\"line\">JAVA_HEAP_MAX=-Xmx1000m</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>core.site.xml</li>\n</ul>\n<p><figure class=\"highlight text\"><figcaption><span>core.site.xml文件配置</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master hadoop]# vi core-site.xml</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">    &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;fs.defaultFS&lt;/name&gt;  </span><br><span class=\"line\">      &lt;value&gt;hdfs://master:8020&lt;/value&gt;  </span><br><span class=\"line\">      &lt;/property&gt;  </span><br><span class=\"line\">    &lt;property&gt;</span><br><span class=\"line\">      &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class=\"line\">      &lt;value&gt;/var/log/hadoop/tmp&lt;/value&gt;</span><br><span class=\"line\">    &lt;/property&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>\n<p>hdfs-site.xml：数据目录<br />\n <figure class=\"highlight text\"><figcaption><span>hdfs-site.xml配置文件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master hadoop]# vi hdfs-site.xml</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;file:///data/hadoop/hdfs/name&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;file:///data/hadoop/hdfs/data&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">     &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class=\"line\">     &lt;value&gt;master:50090&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">     &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class=\"line\">     &lt;value&gt;3&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>\n</li>\n<li>\n<p>mapred-site.xml ：需要拷贝之后再进行设置</p>\n</li>\n</ul>\n<p><figure class=\"highlight text\"><figcaption><span>mapred-site.xml配置文件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master hadoop]# cp mapred-site.xml.template mapred-site.xml</span><br><span class=\"line\">[root@master hadoop]# vi mapred-site.xml</span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;yarn&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br><span class=\"line\">&lt;!-- jobhistory properties --&gt;</span><br><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;master:10020&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">     &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class=\"line\">     &lt;value&gt;master:19888&lt;/value&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>yarn-site.xml</li>\n</ul>\n<p><figure class=\"highlight text\"><figcaption><span>yarn-site.xml配置文件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master hadoop]# vi yarn-site.xml </span><br><span class=\"line\">&lt;configuration&gt;</span><br><span class=\"line\">  &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;master&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;    </span><br><span class=\"line\">  &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8032&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;</span><br><span class=\"line\">  &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8030&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;</span><br><span class=\"line\">  &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8088&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;</span><br><span class=\"line\">  &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.resourcemanager.webapp.https.address&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8090&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;</span><br><span class=\"line\">  &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8031&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;</span><br><span class=\"line\">  &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8033&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;</span><br><span class=\"line\">  &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;/data/hadoop/yarn/local&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;</span><br><span class=\"line\">  &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;true&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;</span><br><span class=\"line\">  &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;/data/tmp/logs&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt; </span><br><span class=\"line\"> &lt;name&gt;yarn.log.server.url&lt;/name&gt; </span><br><span class=\"line\"> &lt;value&gt;http://master:19888/jobhistory/logs/&lt;/value&gt;</span><br><span class=\"line\"> &lt;description&gt;URL for job history server&lt;/description&gt;</span><br><span class=\"line\">&lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;</span><br><span class=\"line\">   &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;false&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;</span><br><span class=\"line\"> &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class=\"line\">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class=\"line\">  &lt;/property&gt;</span><br><span class=\"line\">  &lt;property&gt;</span><br><span class=\"line\">    &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</span><br><span class=\"line\">      &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class=\"line\">      &lt;/property&gt;</span><br><span class=\"line\">&lt;property&gt;  </span><br><span class=\"line\">        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;  </span><br><span class=\"line\">        &lt;value&gt;2048&lt;/value&gt;  </span><br><span class=\"line\"> &lt;/property&gt;  </span><br><span class=\"line\"> &lt;property&gt;  </span><br><span class=\"line\">        &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;  </span><br><span class=\"line\">        &lt;value&gt;512&lt;/value&gt;  </span><br><span class=\"line\"> &lt;/property&gt;   </span><br><span class=\"line\"> &lt;property&gt;  </span><br><span class=\"line\">        &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;  </span><br><span class=\"line\">        &lt;value&gt;4096&lt;/value&gt;  </span><br><span class=\"line\"> &lt;/property&gt; </span><br><span class=\"line\"> &lt;property&gt; </span><br><span class=\"line\">    &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt; </span><br><span class=\"line\">    &lt;value&gt;2048&lt;/value&gt; </span><br><span class=\"line\"> &lt;/property&gt; </span><br><span class=\"line\"> &lt;property&gt; </span><br><span class=\"line\">    &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt; </span><br><span class=\"line\">    &lt;value&gt;2048&lt;/value&gt; </span><br><span class=\"line\"> &lt;/property&gt; </span><br><span class=\"line\"> &lt;property&gt; </span><br><span class=\"line\">    &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt; </span><br><span class=\"line\">    &lt;value&gt;1&lt;/value&gt; </span><br><span class=\"line\"> &lt;/property&gt;</span><br><span class=\"line\">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li><strong>slave</strong></li>\n</ul>\n<p><figure class=\"highlight text\"><figcaption><span>slaves配置文件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master hadoop]# vi slaves</span><br><span class=\"line\">#删除localhost，添加：</span><br><span class=\"line\">slave1</span><br><span class=\"line\">slave2</span><br></pre></td></tr></table></figure></p>\n",
            "tags": [
                "大数据技术与应用",
                "Hadoop"
            ]
        },
        {
            "id": "http://example.com/2020/11/22/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E8%AE%BE%E7%BD%AE%E5%9B%BA%E5%AE%9AIP/",
            "url": "http://example.com/2020/11/22/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E8%AE%BE%E7%BD%AE%E5%9B%BA%E5%AE%9AIP/",
            "title": "2.设置固定IP",
            "date_published": "2020-11-22T04:14:12.620Z",
            "content_html": "<h1 id=\"设置固定ip\"><a class=\"anchor\" href=\"#设置固定ip\">#</a> 设置固定 IP</h1>\n<p>搭建的集群总共 3 台虚拟机，每台虚拟机均使用<strong> NAT 模式</strong>接入网络，为其分配 IP 并保证每台虚拟机的 IP 处于同一子网段内。所有需要配置固定虚拟机的 IP 地址，这里以虚拟机 master 为例，详细介绍虚拟机固定 IP 地址的步骤。</p>\n<ul>\n<li>\n<p>(1) 开启虚拟机并登陆<br />\n <figure class=\"highlight bash\"><figcaption><span>登录提示信息</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CentOS release 6.5 (Final)</span><br><span class=\"line\">Kernel 2.6.32-431.e16.x86_64 on an x86_64</span><br><span class=\"line\">master login: root    <span class=\"comment\"># 输入root账户</span></span><br><span class=\"line\">Pawwword:\t\t\t  <span class=\"comment\"># 输入root账户对应的密码，输入密码回车即可，不会出现占位密码</span></span><br><span class=\"line\">[root@master ~]<span class=\"comment\">#      # 出现所示的信息即登录成功，root：表示登录的帐号名；master：表示主机名，可修改；~：表示所在的目录名称</span></span><br></pre></td></tr></table></figure></p>\n</li>\n<li>\n<p>（2）重启网络服务，查看各接口信息是否正常，输入 “<strong>service network restart</strong>”<br />\n<figure class=\"highlight bash\"><figcaption><span>重启网络服务</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># service network restart</span></span><br><span class=\"line\">Shutting down loopback interface:\t\t[ OK ]</span><br><span class=\"line\">Bringing up loopbak interface: \t\t\t[ OK ]</span><br></pre></td></tr></table></figure></p>\n</li>\n<li>\n<p>（3）查看虚拟机的<strong>虚拟网络编辑器</strong>，如图 2-1 所示；点击切换到<strong> VMent8</strong> 网卡选项，然后点击又下角<strong>更改设置</strong>，如图 2-2 所示；然后再切换到<strong> VMent8</strong> 网卡选项，将 “<strong>使用本地 DHCP 服务将 IP 地址分配给虚拟机（D）</strong>” 勾去掉，如图 2-3 所示；最后点击 “<strong>NAT 设置（S）</strong>”，如图 2-4 所示，记录 “<strong>网关 IP (G)</strong>”，记住前三网段地址，例如：192.168.146。</p>\n</li>\n</ul>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/22/D8Kfwn.jpg\" alt=\"D8Kfwn.jpg\" title=\"图2-1 打开虚拟网络编辑器\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/22/D8Kfwn.md.jpg\" alt=\"D8Kfwn.md.jpg\" title=\"图2-2 虚拟网络编辑器\" /></p>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/22/D8K2Lj.md.jpg\" alt=\"D8K2Lj.md.jpg\" title=\"图2-3 去掉IP自动分配\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/22/D8KgyQ.md.jpg\" alt=\"D8KgyQ.md.jpg\" title=\"图2-4 记录IP网段\" /></p>\n<ul>\n<li>（4）修改配置文件，运行 “<strong>vi /etc/sysconfig/network-scripts/ifcfg-eth0</strong>” 命令<br />\n <figure class=\"highlight bash\"><figcaption><span>查看配置文件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># vi /etc/sysconfig/network-scripts/ifcfg-eth0</span></span><br><span class=\"line\"><span class=\"comment\"># 进入修改的配置文件,正确应该如下所示，如果进入的文件是没有信息的，请仔细检查路径是否正确</span></span><br><span class=\"line\">DEVICE=eth0\t\t\t<span class=\"comment\">#设备名，克隆时需要修改</span></span><br><span class=\"line\">HWADDR=00:0C:29:C4:55:27\t\t\t\t<span class=\"comment\">#网卡地址，克隆时需要修改</span></span><br><span class=\"line\">TYPE=Ethernet</span><br><span class=\"line\">UUID=f994c111-ad56-8178-6c6069d8818c</span><br><span class=\"line\">ONBOOT=no\t\t\t\t<span class=\"comment\">#设置系统启动时是否激活网卡，1、需要修改</span></span><br><span class=\"line\">NM_CONTROLLED=yes\t\t\t\t</span><br><span class=\"line\">BOOTPROTO=dhcp\t\t\t\t<span class=\"comment\">#网络配置模式，总共4种模式 2、需要修改</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n<p>BOOTPROTO 虚拟机的网络模式说明，如下表所示：</p>\n<table>\n<thead>\n<tr>\n<th>网络模式</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>dhcp</td>\n<td>设置网卡绑定的时候通过 DHCP 协议的方法来获得地址</td>\n</tr>\n<tr>\n<td>none</td>\n<td>设置网卡绑定的时候不使用任何协议</td>\n</tr>\n<tr>\n<td>bootp</td>\n<td>设置网卡绑定的时候使用 BOOTP 协议</td>\n</tr>\n<tr>\n<td><strong>static</strong></td>\n<td>设置网卡绑定的时候使用静态协议</td>\n</tr>\n</tbody>\n</table>\n<p>查看和了解完配置信息之后，需要修改<strong>配置文件</strong>，主要修改 onboot、bootproto 以及添加静态 ip 地址信息，修改如下所示，修改完成 “<strong>:wq</strong>” 保存退出。</p>\n<p><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DEVICE&#x3D;eth0\t\t\t</span><br><span class=\"line\">HWADDR&#x3D;00:0C:29:C4:55:27\t\t\t\t</span><br><span class=\"line\">TYPE&#x3D;Ethernet</span><br><span class=\"line\">UUID&#x3D;f994c111-ad56-8178-6c6069d8818c</span><br><span class=\"line\">ONBOOT&#x3D;yes\t\t#1、no修改成yes</span><br><span class=\"line\">NM_CONTROLLED&#x3D;yes\t\t\t\t</span><br><span class=\"line\">BOOTPROTO&#x3D;static\t#2、dhcp修改成static</span><br><span class=\"line\">#添加一下内容</span><br><span class=\"line\">IPADDR&#x3D;192.168.146.171\t\t\t\t#IPADDR前三个子段需要和虚拟网络编辑器一致，最后一个数字需要在0~255之间</span><br><span class=\"line\">NETMASK&#x3D;255.255.255.0\t\t\t\t</span><br><span class=\"line\">GATEWAY&#x3D;192.168.146.2\t\t\t\t#和虚拟网络编辑器网关ip一致</span><br><span class=\"line\">DNS1&#x3D;192.168.146.2\t\t\t\t\t#和GATEWAY保持一致</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>（4）再次重启网络服务并查看 IP，查看 IP 地址是否已经设置成功，如果<strong> inet addr</strong>：出现设置 ip 的地址信息，即 ip 设置成功，并使用 ping 进行网络功能测试。</li>\n</ul>\n<p><figure class=\"highlight bash\"><figcaption><span>重启网络服务并查看IP地址</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># service network restart</span></span><br><span class=\"line\"> Shutting down loopback interface:\t\t[ OK ]</span><br><span class=\"line\"> Bringing up loopbak interface: \t\t\t[ OK ]</span><br><span class=\"line\"> Bringing up interface eth0: Determining <span class=\"keyword\">if</span> ip address 192.168.146.171 is already <span class=\"keyword\">in</span> use <span class=\"keyword\">for</span> device eth0...\t\t\t\t[ OK ]</span><br><span class=\"line\"> [root@master ~]<span class=\"comment\"># service network restart</span></span><br><span class=\"line\"> eth0      Link encap:Ethernet  HWaddr 00:0C:29:C4:55:27  </span><br><span class=\"line\">          inet addr:192.168.146.171  Bcast:192.168.146.255  Mask:255.255.255.0</span><br><span class=\"line\">          inet6 addr: fe80::20c:29ff:fec4:5527/64 Scope:Link</span><br><span class=\"line\">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class=\"line\">          RX packets:41 errors:0 dropped:0 overruns:0 frame:0</span><br><span class=\"line\">          TX packets:49 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class=\"line\">          collisions:0 txqueuelen:1000 </span><br><span class=\"line\">          RX bytes:4743 (4.6 KiB)  TX bytes:5617 (5.4 KiB)</span><br><span class=\"line\"></span><br><span class=\"line\">lo        Link encap:Local Loopback  </span><br><span class=\"line\">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class=\"line\">          inet6 addr: ::1/128 Scope:Host</span><br><span class=\"line\">          UP LOOPBACK RUNNING  MTU:16436  Metric:1</span><br><span class=\"line\">          RX packets:4 errors:0 dropped:0 overruns:0 frame:0</span><br><span class=\"line\">          TX packets:4 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class=\"line\">          collisions:0 txqueuelen:0 </span><br><span class=\"line\">          RX bytes:264 (264.0 b)  TX bytes:264 (264.0 b)</span><br><span class=\"line\">[root@master ~]<span class=\"comment\"># ping wwww.baidu.com</span></span><br><span class=\"line\">PING www.a.shifen.com (36.152.44.95) 56(84) bytes of data.</span><br><span class=\"line\">64 bytes from 36.152.44.95: icmp_seq=1 ttl=128 time=21.2 ms</span><br><span class=\"line\">64 bytes from 36.152.44.95: icmp_seq=2 ttl=128 time=18.4 ms</span><br><span class=\"line\">64 bytes from 36.152.44.95: icmp_seq=3 ttl=128 time=16.6 ms</span><br><span class=\"line\">64 bytes from 36.152.44.95: icmp_seq=4 ttl=128 time=18.6 ms</span><br><span class=\"line\">^C</span><br><span class=\"line\">--- www.a.shifen.com ping statistics ---</span><br><span class=\"line\">5 packets transmitted, 4 received, 20% packet loss, time 4024ms</span><br><span class=\"line\">rtt min/avg/max/mdev = 16.668/18.752/21.232/1.626 ms</span><br><span class=\"line\"><span class=\"comment\"># ctrl+c 键进行结束</span></span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>\n<p>(5) 远程连接虚拟机</p>\n<p>在 VMWare 的虚拟机窗口中操作 Linux 系统非常不方便，比如无法复制和粘贴，因此推荐使用 Xshell 远程连接 Linux 系统。打开 xshell 软件，并点击<strong>文件</strong>菜单，在出现的菜单栏中选择 “<strong>新建</strong>” 命令，如图 2-5 所示；配置新建的的会话窗口，在连接的信息中，名称可以自己填写，主机就是刚刚配置的 IP 地址，端口号默认，配置完成点击确定即可，如图 2-6 所示；在新建完会话后，在会话窗口可以看见刚刚新建的会话，点击新建的会话并连接，如图 2-7 所示；弹出登录的用户和密码，输入对应的信息即可，在输入的时候都可以点击保存，下次再登录不用再输入，如图 2-8、3-9 所示；输入信息无误后，就可以显示登录成功，如图 2-10 所示。</p>\n</li>\n</ul>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/22/D8Gets.jpg\" alt=\"D8GK10.md.jpg\" title=\"图2-5 新建\" /></p>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/22/D8Gmhn.jpg\" alt=\"D8Gupq.md.jpg\" title=\"图2-6 配置信息\" /></p>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/22/D8Gupq.jpg\" alt=\"D8Gmhn.md.jpg\" title=\"图2-7 会话窗口\" /></p>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/22/D8GE7Q.jpg\" alt=\"D8Gets.md.jpg\" title=\"图2-8 用户名\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/22/D8GZkj.jpg\" alt=\"D8GZkj.md.jpg\" title=\"图2-9 密码\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/22/D8GK10.jpg\" alt=\"D8GE7Q.md.jpg\" title=\"图2-10 登录成功\" /></p>\n<h1 id=\"虚拟机在线安装软件\"><a class=\"anchor\" href=\"#虚拟机在线安装软件\">#</a> 虚拟机在线安装软件</h1>\n<h2 id=\"rpm工具本地包安装\"><a class=\"anchor\" href=\"#rpm工具本地包安装\">#</a> RPM 工具：本地包安装</h2>\n<p>RPM 是”Redhat Package Manager” 的缩写，根据名字也能猜到这是 Redhat 公司开发出来的。RPM 是以一种数据库记录的方式来将你所需要的套件安装到你的 Linux 主机的一套管理程序。也就是说，你的 linux 系统中存在着一个关于 RPM 的数据库，它记录了安装的包以及包与包之间依赖相关性。RPM 包是预先在 linux 机器上编译好并打包好的文件，安装起来非常快捷。但是也有一些缺点，比如安装的环境必须与编译时的环境一致或者相当；包与包之间存在着相互依赖的情况；卸载包时需要先把依赖的包卸载掉，如果依赖的包是系统所必须的，那就不能卸载这个包，否则会造成系统崩溃。<br />\n每一个 rpm 包的名称都由”-“和”.” 分成了若干部分。就拿 a2ps-4.13b-57.2.el5.i386.rpm 这个包来解释一下，a2ps 为包名；4.13b 则为版本信息；57.2.el5 为发布版本号；i386 为运行平台。其中运行平台常见的有 i386, i586, i686, x86_64 ，需要你注意的是 cpu 目前是分 32 位和 64 位的，i386,i586 和 i686 都为 32 位平台，x86_64 则代表为 64 位的平台。另外有些 rpm 包并没有写具体的平台而是 noarch，这代表这个 rpm 包没有硬件平台限制。例如 alacarte-0.10.0-1.fc6.noarch.rpm<br />\nRPM 管理支持事务机制。增强了程序安装卸载的管理。</p>\n<ul>\n<li>RPM 的功能：<br />\n打包、安装、查询、升级、卸载、校验、数据库管理。</li>\n<li>RPM 的缺点:<br />\n 由于 Linux 中的程序大多是小程序。程序与程序之间存在非常复杂的依赖关系。RPM 无法解决软件包的依赖关系。</li>\n<li>RPM 包<br />\n用 RPM 工具可以将二进制程序进行打包，包被称为 RPM 包。RPM 包并不是跨平台的</li>\n</ul>\n<h2 id=\"yum工具联网安装\"><a class=\"anchor\" href=\"#yum工具联网安装\">#</a> yum 工具：联网安装</h2>\n<p>介绍完 rpm 工具后，还需要你掌握最常用的 yum 工具，这个工具比 rpm 工具好用多了，当然前提是你使用的 linux 系统是支持 yum 的。yum 最大的优势在于可以联网去下载所需要的 rpm 包，然后自动安装，在这个工程中如果要安装的 rpm 包有依赖关系，yum 会帮你解决掉这些依赖关系依次安装所有 rpm 包。</p>\n<p>yum 的命令格式一般如下：</p>\n<p><figure class=\"highlight bash\"><figcaption><span>yum的命令格式</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum [options] [<span class=\"built_in\">command</span>] [packages..]</span><br></pre></td></tr></table></figure><br />\n[options] 可选参数说明如下：</p>\n<table>\n<thead>\n<tr>\n<th>选项</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>-h</td>\n<td>显示帮助信息</td>\n</tr>\n<tr>\n<td>-y</td>\n<td>对所有的提问都回答 “yes”</td>\n</tr>\n<tr>\n<td>-c</td>\n<td>指定配置文件</td>\n</tr>\n<tr>\n<td>-q</td>\n<td>安静模式</td>\n</tr>\n<tr>\n<td>-v</td>\n<td>详细模式</td>\n</tr>\n<tr>\n<td>-d</td>\n<td>设置调试等级（0-10）</td>\n</tr>\n<tr>\n<td>-e</td>\n<td>设置错误等级（0-10）</td>\n</tr>\n<tr>\n<td>-R</td>\n<td>设置 yum 出来一个命令的最大等待时间</td>\n</tr>\n<tr>\n<td>-C</td>\n<td>完全从缓存中运行，而不去下载或者更新任何文件</td>\n</tr>\n</tbody>\n</table>\n<p>[command] 为所要进行的操作，如下所示：</p>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>install</td>\n<td>安装 RPM 软件包</td>\n</tr>\n<tr>\n<td>update</td>\n<td>更新 RPM 软件包</td>\n</tr>\n<tr>\n<td>check-update</td>\n<td>检查是否有可用的 RPM 软件包更新</td>\n</tr>\n<tr>\n<td>remove</td>\n<td>删除指定的 RPM 软件包</td>\n</tr>\n<tr>\n<td>list</td>\n<td>显示软件包信息</td>\n</tr>\n<tr>\n<td>search</td>\n<td>检查软件包信息</td>\n</tr>\n<tr>\n<td>info</td>\n<td>显示指定的 RPM 软件包的描述信息和概要信息</td>\n</tr>\n<tr>\n<td>clean</td>\n<td>清理 yum 过期的缓存</td>\n</tr>\n<tr>\n<td>resolvedep</td>\n<td>显示 RPM 软件包的依赖关系</td>\n</tr>\n<tr>\n<td>localinstall</td>\n<td>安装本地 RPM 软件包</td>\n</tr>\n<tr>\n<td>localupdate</td>\n<td>更新本地 RPM 软件包</td>\n</tr>\n<tr>\n<td>deplist</td>\n<td>显示 RPM 软件包的所有依赖关系</td>\n</tr>\n</tbody>\n</table>\n<p>在 xshell 给虚拟机安装软件：<strong>安装 vim（类似 vi）、openssh-server（连接服务）、openssh-clients（客户端）</strong></p>\n<p><figure class=\"highlight bash\"><figcaption><span>yum安装软件</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[root@master ~]<span class=\"comment\"># yum install -y vim openssh-server openssh-clients</span></span><br></pre></td></tr></table></figure></p>\n<div class=\"note info\">\n<p>yum 安装软件只是测试安装，熟悉 yum 安装过程，上述软件在 hadoop 搭建过程中不作要求安装。</p>\n</div>\n<h1 id=\"可能出现的问题\"><a class=\"anchor\" href=\"#可能出现的问题\">#</a> 可能出现的问题</h1>\n<details class=\"danger\"><summary>IP地址没有修改成功？</summary><div>\n<p><strong>请仔细查看修改的配置文件是否正确</strong></p>\n</div></details>\n<details class=\"danger\"><summary>虚拟机网络设置成功并能够上网，但是Xshell无法连接虚拟机？</summary><div>\n<p><div class=\"links\"><div class=\"item\" title=\"yujz\" style=\"--block-color:#e9546b;\"><span class=\"exturl image\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljcTUyMTEzMS9hcnRpY2xlL2RldGFpbHMvODMyNDU0ODA=\" data-background-image=\"https://cdn.jsdelivr.net/gh/amehime/shoka@latest/images/avatar.jpg\"></span>\n          <div class=\"info\">\n          <span class=\"exturl title\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ljcTUyMTEzMS9hcnRpY2xlL2RldGFpbHMvODMyNDU0ODA=\">解决方案</span>\n          <p class=\"desc\">自定义配置虚拟机的IP地址</p>\n          </div></div></div></p>\n</div></details>\n",
            "tags": [
                "大数据技术与应用",
                "Hadoop"
            ]
        },
        {
            "id": "http://example.com/2020/11/20/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/",
            "url": "http://example.com/2020/11/20/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/",
            "title": "1.安装及配置虚拟机",
            "date_published": "2020-11-20T15:08:41.080Z",
            "content_html": "<h1 id=\"安装及配置虚拟机\"><a class=\"anchor\" href=\"#安装及配置虚拟机\">#</a> 安装及配置虚拟机</h1>\n<p>在个人计算机安装 Linux 虚拟机，以远程访问的方式对其进行管理，并在线安装常用的软件包。</p>\n<h2 id=\"创建linux虚拟机\"><a class=\"anchor\" href=\"#创建linux虚拟机\">#</a> 创建 Linux 虚拟机</h2>\n<p>VMware Workstaion 是一款功能强大的虚拟机软件，在不影响本机操作系统的情况下，用户可以在虚拟机中同时运行不同版本的操作系统。安装 VMware Workstaion 的过程比较简单，双击下载后的 VMware-workstation-full-11.0.0-2305329.exe，选择安装目录，然后点击 “下一步” 按钮，继续安装，之后输入产品系列号，安装完成后即可安装 Centos 6.5 操作系统。</p>\n<p>接下来在安装好的 VMware 上安装 CentOS 6.5 系统。安装步骤如下。</p>\n<p>（1）打开安装好的 VMware 虚拟机，选择 “创建新的虚拟机” 选项，如下图 1-2 所示。</p>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/19/DK8UJS.png\" alt=\"Dn4akV.png\" title=\"图 1-2 创建新的虚拟机”\" /></p>\n<p>（2）此时进入到新建虚拟机向导，选择 “典型（推荐）” 模式在点击 “下一步” 按钮如图 1-3 所示。<br />\n（3）安装客户机操作系统，选择 “稍后安装操作系统” 单选按钮，然后单击 “下一步” 按钮，如图所示 1-4 所示。</p>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/19/DK8aRg.png\" alt=\"Dn4akV.png\" title=\"图 1-3 创建新的虚拟机”\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/19/DK8Ni8.png\" alt=\"Dn4akV.png\" title=\"图 1-4 选择安装客户机操作系统的来源\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/19/DK8YIf.png\" alt=\"DK8YIf.png\" title=\"图1-5 选择客户机操作系统\" /></p>\n<p>（4）选择客户机操作系统，这里选择的是 “Linux（L）” 单选按钮，版本是 CentOS 64 位，选择好之后直接单击 “下一步” 按钮，如图 1-5 所示。<br />\n（5）命名虚拟机，首先在 E 盘（<strong>注意</strong>：这个可以根据电脑情况选择，建议选择储存容量大的硬盘，不要选择 C 盘）创建一个文件，并在该文件夹下创建一个以 master 命名的文件夹，虚拟机的名称为 “master”，位置为 “E:\\hadoop\\master”，如图 1-6 所示。</p>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/19/DK8dzQ.png\" alt=\"DK8dzQ.png\" title=\"图1-6 命名虚拟机并选择位置\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/19/DK8Bss.md.png\" alt=\"DK8Bss.md.png\" title=\"图1-7 指定磁盘容量\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/19/DK8DLn.md.png\" alt=\"DK8DLn.md.png\" title=\"图1-8 准备创建虚拟机\" /></p>\n<p>（6）指定磁盘容量，指定最大磁盘大小为 “20GB”，选择将 “将虚拟磁盘拆分成多个文件（M）” 单选按钮，单击 “下一步” 按钮，如图 1-7 所示。<br />\n（7）装备创建虚拟机，单机 “自定义硬件” 按钮，如图 1-8 所示，进入硬件设置界面。<br />\n（8，选择 “新 CD/DVD (IDE)” 所在行，在右边的 “连接” 组中选择 “使用 ISO 映像文件” 单选按钮，并指定 CentOS-6.5-x86_64-minimal.iso 的位置，选择网络适配器的模式为 NAT（<span class=\"exturl\" data-url=\"aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1MDQ4NzEzL2FydGljbGUvZGV0YWlscy8xMDU5OTUwMjI=\">模式说明</span>），移除 USB 控制器、声卡和打印机硬件，如图 1-9 所示，最后单机 “关闭” 按钮。返回图 1-9，单机 “完成” 按钮。<br />\n<img data-src=\"https://s3.ax1x.com/2020/11/19/DK8sZq.png\" alt=\"DK8sZq.png\" title=\"图1-9 自定义硬件\" /><br />\n（9）打开虚拟机，选择虚拟机 “master”，选择 “开启虚拟机” 选项，如图 1-10 所示。</p>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/19/DK8yd0.png\" alt=\"DK8yd0.png\" title=\"图1-10 开启虚拟机\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/19/DK8giT.png\" alt=\"DK8giT.png\" title=\"图1-11 CentOS 6.5 安装界面\" /></p>\n<p>（10）打开虚拟机之后看到 CentOS 6.5 的安装界面，按下 “Tab” 键可以选择接下来的操作，也可以不选择，60s 之后系统会自动进入下一步，这里选择第一项，如图 1-11 所示。</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">选项</th>\n<th style=\"text-align:center\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Install or upgrade an existing system</td>\n<td style=\"text-align:center\">安装或升级现有的系统</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Install system with basic video driver</td>\n<td style=\"text-align:center\">安装过程中采用基本的显卡驱动</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Rescue install system</td>\n<td style=\"text-align:center\">进入系统修复模式</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Boot from local drive</td>\n<td style=\"text-align:center\">退出安装，从磁盘启动</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Memory test</td>\n<td style=\"text-align:center\">内存检测</td>\n</tr>\n</tbody>\n</table>\n<p>（11）弹出 “Disc Found” 对话框，选择 “OK” 来测试安装媒体，即 DVD 光盘，如图 1-12 所示、选择 “Skip” 表示跳过，进入下一个界面之后直接单击 “Next” 按钮，这里选择 “Skip” 跳过测试环节。</p>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/19/DK86oV.png\" alt=\"DK86oV.png\" /></p>\n<p>（12）选择安装的语言，这里选择 “Englisg（English）”，如图 1-13 所示。</p>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/19/DK82JU.png\" alt=\"DK82JU.png\" title=\"图1-13 选择安装语言\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/19/DK8RWF.png\" alt=\"DK8RWF.png\" title=\"图1-14 选择键盘\" /></p>\n<p>（13）选择键盘，选择默认的 “U.S English”，如图 1-14 所示。<br />\n（14）选择安装的储存设备，一般都是安装到本地磁盘，所有选择 “Basic Storage Devices” 单击按钮，然后单击 “Next” 按钮，如图 1-15 所示。</p>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/19/DK8Wz4.png\" alt=\"DK8Wz4.png\" title=\"图1-15 选择安装的储存设备\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/19/DK8hQJ.png\" alt=\"DK8hQJ.png\" title=\"图1-16 提醒用户是否删除数据\" /></p>\n<p>（15）这时会弹出警示信息对话框，提醒用户是否需要删除检测到的这个硬盘的所有数据，在此直接单击 “Yes，discard any data” 按钮，如图 1-16 所示。<br />\n（16）设置主机名为 “master”，单击 “Next” 按钮，如图 1-17 所示。</p>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/19/DK84y9.png\" alt=\"DK84y9.png\" title=\"图1-17 设置主机名\" /></p>\n<p>（17）选择时区，这里选择 “Asia/Shanghai”，单击 “Next” 按钮，如图 1-18 所示。</p>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/19/DK8oe1.png\" alt=\"DK8oe1.png\" title=\"图1-18 选择时区\" /></p>\n<p>（18） 设置管理员密码，本集群所有节点的管理员密码都设置为 **“123456”**，如图 1-19 所示。如果密码设置过于简单，系统就会弹出一个提示对话框，在此单击 “Use Anyway” 按钮进行确认，如图 1-19 所示。</p>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/19/DK85LR.png\" alt=\"DK85LR.png\" title=\"图1-19 设置root密码\" /></p>\n<p>（19）接下来是分区与安装的界面，选择 “Use All Space” 单选按钮，如图 1-20 所示。单击 “Next” 按钮，会提示确认格式化并写入数据，单击 “Write changes to disk” 按钮，如图 1-21 所示。</p>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/19/DK8Tdx.png\" alt=\"DK8Tdx.png\" title=\"图1-20 分区与安装\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/19/DK87o6.png\" alt=\"DK87o6.png\" title=\"图1-21 提示确认格式化与写入数据\" /></p>\n<p>（20）开始安装的过程，如图 1-22 所示。</p>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/19/DK8qJO.png\" alt=\"DK8qJO.png\" title=\"图1-22 开始安装\" /></p>\n<p>（21）安装完成，单击 “reboot” 按钮，如图 1-23 所示，进入 CentOS 系统。</p>\n<p class=\"gallery\" data-height=\"180\"><img data-src=\"https://s3.ax1x.com/2020/11/19/DK8bFK.png\" alt=\"DK8bFK.png\" title=\"图1-23 安装完成\" /><br />\n<img data-src=\"https://s3.ax1x.com/2020/11/19/DK8LWD.png\" alt=\"DK8LWD.png\" title=\"图1-24 登录\" /></p>\n<p>（22）登录，输入用户名 “root” 以及密码 “123456”，如图 1-24 所示。</p>\n",
            "tags": [
                "大数据技术与应用",
                "Hadoop"
            ]
        },
        {
            "id": "http://example.com/2020/11/20/%E7%9F%A5%E8%AF%86%E6%8B%93%E5%B1%95/%E8%B6%A3%E5%91%B3%E6%9D%82%E8%B0%88/%E5%AE%9E%E8%AE%AD%E5%91%A8%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/",
            "url": "http://example.com/2020/11/20/%E7%9F%A5%E8%AF%86%E6%8B%93%E5%B1%95/%E8%B6%A3%E5%91%B3%E6%9D%82%E8%B0%88/%E5%AE%9E%E8%AE%AD%E5%91%A8%E7%9F%A5%E8%AF%86%E7%82%B9%E8%A1%A5%E5%85%85/",
            "title": "实训周知识点补充",
            "date_published": "2020-11-20T12:45:54.409Z",
            "content_html": "<h1 id=\"实训周知识点补充\"><a class=\"anchor\" href=\"#实训周知识点补充\">#</a> 实训周知识点补充</h1>\n<h3 id=\"一-jdk的安装与配置\"><a class=\"anchor\" href=\"#一-jdk的安装与配置\">#</a> 一、JDK 的安装与配置</h3>\n<p><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">print(<span class=\"string\">&#x27;hello world&#x27;</span>)</span><br></pre></td></tr></table></figure></p>\n<p>&lt;!----&gt;</p>\n<hr />\n",
            "tags": []
        },
        {
            "id": "http://example.com/2020/11/20/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/Hadoop%E5%AE%89%E8%A3%85%E4%BB%BB%E5%8A%A1%E8%83%8C%E6%99%AF/",
            "url": "http://example.com/2020/11/20/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/Hadoop%E5%AE%89%E8%A3%85%E4%BB%BB%E5%8A%A1%E8%83%8C%E6%99%AF/",
            "title": "Hadoop平台搭建任务背景",
            "date_published": "2020-11-19T16:01:52.864Z",
            "content_html": "<div class=\"note primary\">\n<p>1、<span class=\"exturl\" data-url=\"aHR0cHM6Ly9nb2Zpc2hlci5naXRodWIuaW8vMjAyMC8xMS8yMC8lRTUlOUMlQTglRTclQkElQkYlRTglQUYlQkUlRTclQTglOEIvJUU1JUE0JUE3JUU2JTk1JUIwJUU2JThEJUFFJUU2JThBJTgwJUU2JTlDJUFGJUU0JUI4JThFJUU1JUJBJTk0JUU3JTk0JUE4LyVFNSVBRSU4OSVFOCVBMyU4NSVFNSU4RiU4QSVFOSU4NSU4RCVFNyVCRCVBRSVFOCU5OSU5QSVFNiU4QiU5RiVFNiU5QyVCQS8=\">安装及配置虚拟机</span><br />\n 2、<span class=\"exturl\" data-url=\"aHR0cHM6Ly9nb2Zpc2hlci5naXRodWIuaW8vMjAyMC8xMS8yMi8lRTUlOUMlQTglRTclQkElQkYlRTglQUYlQkUlRTclQTglOEIvJUU1JUE0JUE3JUU2JTk1JUIwJUU2JThEJUFFJUU2JThBJTgwJUU2JTlDJUFGJUU0JUI4JThFJUU1JUJBJTk0JUU3JTk0JUE4LyVFOCVBRSVCRSVFNyVCRCVBRSVFNSU5QiVCQSVFNSVBRSU5QUlQLw==\">设置固定 IP</span><br />\n3、<span class=\"exturl\" data-url=\"aHR0cHM6Ly9nb2Zpc2hlci5naXRodWIuaW8vMjAyMC8xMi8wMi8lRTUlOUMlQTglRTclQkElQkYlRTglQUYlQkUlRTclQTglOEIvJUU1JUE0JUE3JUU2JTk1JUIwJUU2JThEJUFFJUU2JThBJTgwJUU2JTlDJUFGJUU0JUI4JThFJUU1JUJBJTk0JUU3JTk0JUE4LyVFNSVBRSU4OSVFOCVBMyU4NUpESyVFNSU4RiU4QUhhZG9vcC8=\">安装 JDK 及 Hadoop</span><br />\n4、<span class=\"exturl\" data-url=\"aHR0cHM6Ly9nb2Zpc2hlci5naXRodWIuaW8vMjAyMC8xMi8wMi8lRTUlOUMlQTglRTclQkElQkYlRTglQUYlQkUlRTclQTglOEIvJUU1JUE0JUE3JUU2JTk1JUIwJUU2JThEJUFFJUU2JThBJTgwJUU2JTlDJUFGJUU0JUI4JThFJUU1JUJBJTk0JUU3JTk0JUE4LyVFNiU5NyVCNiVFOSU5NyVCNCVFNSU5MCU4QyVFNiVBRCVBNSVFNiU5QyU4RCVFNSU4QSVBMSVFMyU4MCU4MSVFNSU4NSVCMyVFOSU5NyVBRCVFOSU5OCVCMiVFNyU4MSVBQiVFNSVBMiU5OSVFMyU4MCU4MUlQJUU2JTk4JUEwJUU1JUIwJTg0Lw==\">时间同步服务、关闭防火墙、IP 映射</span><br />\n 5、<span class=\"exturl\" data-url=\"aHR0cHM6Ly9nb2Zpc2hlci5naXRodWIuaW8vMjAyMC8xMi8wMi8lRTUlOUMlQTglRTclQkElQkYlRTglQUYlQkUlRTclQTglOEIvJUU1JUE0JUE3JUU2JTk1JUIwJUU2JThEJUFFJUU2JThBJTgwJUU2JTlDJUFGJUU0JUI4JThFJUU1JUJBJTk0JUU3JTk0JUE4LyVFNSU4NSU4QiVFOSU5QSU4NiVFOCU4QSU4MiVFNyU4MiVCOSVFOSU4NSU4RCVFNyVCRCVBRSVFNCVCRiVBRSVFNiU5NCVCOS8=\">克隆节点配置修改</span><br />\n 6、<span class=\"exturl\" data-url=\"aHR0cHM6Ly9nb2Zpc2hlci5naXRodWIuaW8vMjAyMC8xMi8wMi8lRTUlOUMlQTglRTclQkElQkYlRTglQUYlQkUlRTclQTglOEIvJUU1JUE0JUE3JUU2JTk1JUIwJUU2JThEJUFFJUU2JThBJTgwJUU2JTlDJUFGJUU0JUI4JThFJUU1JUJBJTk0JUU3JTk0JUE4LyVFOSU4NSU4RCVFNyVCRCVBRSVFNSU4NSU4RCVFNSVBRiU4NiVFNyVBMCU4MSVFNyU5OSVCQiVFNSVCRCU5NS8=\">配置免密码登录</span><br />\n 7、<span class=\"exturl\" data-url=\"aHR0cHM6Ly9nb2Zpc2hlci5naXRodWIuaW8vMjAyMC8xMi8wMi8lRTUlOUMlQTglRTclQkElQkYlRTglQUYlQkUlRTclQTglOEIvJUU1JUE0JUE3JUU2JTk1JUIwJUU2JThEJUFFJUU2JThBJTgwJUU2JTlDJUFGJUU0JUI4JThFJUU1JUJBJTk0JUU3JTk0JUE4LyVFNSU5MCVBRiVFNSU4QSVBOEhhZG9vcCVFOSU5QiU4NiVFNyVCRSVBNC8=\">启动 Hadoop 集群</span></p>\n</div>\n<div class=\"note info\">\n<p>完全分布式搭建 Hadoop 平台</p>\n</div>\n<h1 id=\"任务背景\"><a class=\"anchor\" href=\"#任务背景\">#</a> 任务背景</h1>\n<p>本文档较为细致地演示在个人计算机上搭建 Hadoop 完全分布式环境的过程。为了保证能较顺畅地运行 Hadoop 集群，并可以进行基本的大数据开发调试，建议个人计算机硬件最低配置为：内存至少 8GB，硬盘可用容量至少 100GB，CPU 为 Intel i3 以上的处理器。在搭建完全分布式集群之前，还需要准备好必要的软件包，主要的软件和版本如下表所示。</p>\n<table>\n<thead>\n<tr>\n<th>软件</th>\n<th>版本</th>\n<th>安装包</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Linux OS</td>\n<td>Centos6.5</td>\n<td>CentOS-6.5-x86_64-minimal.iso</td>\n<td>64 位</td>\n</tr>\n<tr>\n<td>JDK</td>\n<td>1.7+</td>\n<td>jdk-7u79-linux-x64.tar.gz</td>\n<td>64 位</td>\n</tr>\n<tr>\n<td>VMware</td>\n<td>11</td>\n<td>VMware-workstation-full-11.0.0-2305329.exe</td>\n<td></td>\n</tr>\n<tr>\n<td>Hadoop</td>\n<td>2.6.0</td>\n<td>hadoop-2.6.0.tar_4.gz</td>\n<td></td>\n</tr>\n<tr>\n<td>Eclipse</td>\n<td>Neon.3 Release (4.6.3)</td>\n<td>eclipse-jee-neon-3-win32-x86_64.zip</td>\n<td>已编译好的安装包</td>\n</tr>\n<tr>\n<td>Eclipse Hadoop 插件</td>\n<td>2.6.0</td>\n<td>hadoop-eclipse-plugin-2.6.0.jar</td>\n<td>64 位</td>\n</tr>\n<tr>\n<td>SSH 连接工具</td>\n<td>6</td>\n<td>Xshell-6.0.0204p.exe</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>Hadoop 完全分布式集群是典型的主从架构，一般需要使用多台服务器来组建。本文集群的拓扑图如下所示，请注意各个服务器的 IP 与名称，在后续的配置工作中将会经常被使用。  图 1-1 Hadoop 集群的拓扑结构 注意事项：如果在虚拟机中设置 ip 时，注意虚拟网络编辑器中的 ip。</p>\n<p><img data-src=\"https://s3.ax1x.com/2020/11/18/DeQIHg.md.png\" alt=\"DeQIHg.md.png\" title=\"图1-1 Hadoop集群拓扑结构\" /></p>\n<p><span class=\"red\">注意事项</span>：如果在虚拟机中设置 ip 时，注意虚拟网络编辑器中的 ip。</p>\n",
            "tags": [
                "大数据技术与应用",
                "Hadoop"
            ]
        },
        {
            "id": "http://example.com/2020/11/14/%E6%97%A5%E5%B8%B8%E7%A7%AF%E7%B4%AF/%E6%AF%8F%E5%91%A8%E4%B8%80%E7%BB%83/demo2/",
            "url": "http://example.com/2020/11/14/%E6%97%A5%E5%B8%B8%E7%A7%AF%E7%B4%AF/%E6%AF%8F%E5%91%A8%E4%B8%80%E7%BB%83/demo2/",
            "title": "demo2",
            "date_published": "2020-11-14T12:27:26.000Z",
            "content_html": "<p>你这个坏孩子，没有人怪你啊</p>\n<p>sss</p>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2020/11/14/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/Linux%E7%BD%91%E7%BB%9C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/demo2/",
            "url": "http://example.com/2020/11/14/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/Linux%E7%BD%91%E7%BB%9C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/demo2/",
            "title": "demo2",
            "date_published": "2020-11-14T12:27:26.000Z",
            "content_html": "<p>你这个坏孩子，没有人怪你啊</p>\n<p>sss</p>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2020/11/14/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E6%95%B0%E6%8D%AE%E5%BA%93/demo2/",
            "url": "http://example.com/2020/11/14/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E6%95%B0%E6%8D%AE%E5%BA%93/demo2/",
            "title": "demo2",
            "date_published": "2020-11-14T12:27:26.000Z",
            "content_html": "<p>你这个坏孩子，没有人怪你啊</p>\n<p>sss</p>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2020/11/14/%E7%A8%8B%E5%BA%8F%E4%BB%A3%E7%A0%81/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/demo2/",
            "url": "http://example.com/2020/11/14/%E7%A8%8B%E5%BA%8F%E4%BB%A3%E7%A0%81/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/demo2/",
            "title": "demo2",
            "date_published": "2020-11-14T12:27:26.000Z",
            "content_html": "<p>你这个坏孩子，没有人怪你啊</p>\n<p>sss</p>\n",
            "tags": []
        }
    ]
}