<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://example.com</id>
    <title>余心所善，九死未悔！ • Posts by &#34;hive安装教程&#34; category</title>
    <link href="http://example.com" />
    <updated>2021-12-01T16:49:21.872Z</updated>
    <category term="大数据技术与应用" />
    <category term="Hive" />
    <category term="Hadoop" />
    <entry>
        <id>http://example.com/2021/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/Hive%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%93%8D%E4%BD%9C/</id>
        <title>Hive数据类型操作</title>
        <link rel="alternate" href="http://example.com/2021/12/02/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/Hive%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%93%8D%E4%BD%9C/"/>
        <content type="html">&lt;h1 id=&#34;hive数据类型操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hive数据类型操作&#34;&gt;#&lt;/a&gt; Hive 数据类型操作&lt;/h1&gt;
&lt;h2 id=&#34;hive内部表操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hive内部表操作&#34;&gt;#&lt;/a&gt; Hive 内部表操作&lt;/h2&gt;
&lt;h3 id=&#34;针对基本类型建表&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#针对基本类型建表&#34;&gt;#&lt;/a&gt; 针对基本类型建表&lt;/h3&gt;
&lt;p&gt;首先，在 master 机器的 &lt;code&gt;/export/data&lt;/code&gt;  目录下创建 hivedata 目录，在改文件夹下创建 &lt;code&gt;user.txt&lt;/code&gt; ，并添加如下数据内容：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight txt&#34;&gt;&lt;figcaption&gt;&lt;span&gt;测试数据内容&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1,allen,18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2,tom,23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3,jerry,28&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;具体操作如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# mkdir -p /export/data/hivedata&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# cd /export/data/hivedata/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;# vi user.txt &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;# cat user.txt &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;1,allen,18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2,tom,23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3,jerry,28&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;启动 hadoop 和 hive, 具体如下操作&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;bash代码&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master data]&lt;span class=&#34;comment&#34;&gt;# sh /usr/local/hadoop-2.6.5/sbin/start-all.sh&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master data]&lt;span class=&#34;comment&#34;&gt;# sh /export/servers/apache-hive-1.2.1-bin/bin/hive&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://gitee.com/vickyFish/typora_pic/raw/master/images/image-20211201232425173.png&#34; alt=&#34;image-20211201232425173&#34; /&gt;&lt;/p&gt;
&lt;p&gt;在 hive 界面输入 &lt;code&gt;set hive.cli.print.current.db=true&lt;/code&gt;  设置显示当前使用数据库，然后创建 &lt;code&gt;zjdf&lt;/code&gt;  数据库，创建数据库后可以使用 &lt;code&gt;show databases&lt;/code&gt;  命令进行查看，如果已经存在，可以使用 &lt;code&gt;drop database database_name cascade&lt;/code&gt;  命令强制性删除，如果有表格，一定要添加 &lt;code&gt;cascade&lt;/code&gt;  参数，用 &lt;code&gt;use&lt;/code&gt;  切换到这个新建的数据库，并创建内部表 &lt;code&gt;t_user&lt;/code&gt; , 具体操作如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;figcaption&gt;&lt;span&gt;hive界面命令&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive&amp;gt; set hive.cli.print.current.db&amp;#x3D;true;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (default)&amp;gt; show databases;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;default&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.023 seconds, Fetched: 1 row(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (default)&amp;gt; create database zjdf;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.182 seconds、  &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (default)&amp;gt; show databases;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;default&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;zjdf&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.016 seconds, Fetched: 2 row(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (default)&amp;gt; use zjdf;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.024 seconds&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://gitee.com/vickyFish/typora_pic/raw/master/images/image-20211201233838557.png&#34; alt=&#34;image-20211201233838557&#34; /&gt;&lt;/p&gt;
&lt;p&gt;针对 hivedata 目录准备的结构化文件 user.txt 先创建一个内部表 t_user，具体示例如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; create table t_user(id int,name string,age int) ROW FORMAT DELIMITED FIELDS TERMINATED BY &amp;#39;,&amp;#39;;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.561 seconds&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; show tables;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;t_user&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.037 seconds, Fetched: 1 row(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;创建成功后，通过 WEB UI 界面打开 Hive 内部表所在 HDFS 路径（默认 /user/hive/warehouse/zidj.db/t_user）进行查看，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://gitee.com/vickyFish/typora_pic/raw/master/images/image-20211201234130736.png&#34; alt=&#34;image-20211201234130736&#34; /&gt;&lt;/p&gt;
&lt;p&gt;复制 master 终端，然后点击选项卡排列，可以达到左右分屏的效果，如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://gitee.com/vickyFish/typora_pic/raw/master/images/image-20211201234439467.png&#34; alt=&#34;image-20211201234439467&#34; /&gt;&lt;/p&gt;
&lt;p&gt;将准备好的 user.txt 移动到 hadoop 对应的 t_user 表的路径中，具体操作如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;# hadoop fs -put user.txt /user/hive/warehouse/zjdf.db/t_user&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21/12/01 10:05:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; your platform... using builtin-java classes &lt;span class=&#34;built_in&#34;&gt;where&lt;/span&gt; applicable&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;刷新 Hadoop 文件系统，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://gitee.com/vickyFish/typora_pic/raw/master/images/image-20211201234942510.png&#34; alt=&#34;image-20211201234942510&#34; /&gt;&lt;/p&gt;
&lt;p&gt;在 hive 界面中查询 t_user 表数据，发现表中已经存在数据，具体命令如下：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; select * from t_user;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;1	allen	18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2	tom	23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3	jerry	28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.476 seconds, Fetched: 3 row(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://gitee.com/vickyFish/typora_pic/raw/master/images/image-20211201235147810.png&#34; alt=&#34;image-20211201235147810&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;针对复杂类型建表&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#针对复杂类型建表&#34;&gt;#&lt;/a&gt; 针对复杂类型建表&lt;/h3&gt;
&lt;p&gt;例如，现有结构化数据文件 student.txt，文件内容如下所示。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1,zhangsan,唱歌:非常喜欢-跳舞:喜欢-游泳:一般般&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2,lisi,打游戏:非常喜欢-篮球:不喜欢&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;通过对 student.txt 文件内容分析得出，可以设计为 3 列字段，即编号、姓名、兴趣，其中编号可以为 int 类型，姓名可以为 string 类型，而兴趣列还需要进一步分隔为 Map 类型，因此在创建 student.txt 文件对应的内部表语句如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; create table t_student(id int,name string,hobby map&amp;lt;string,string&amp;gt;) row format delimited fields terminated by &amp;#39;,&amp;#39;  collection items terminated by &amp;#39;-&amp;#39; map keys terminated by &amp;#39;:&amp;#39;;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.064 seconds&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; show tables;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;t_student&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;t_user&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.03 seconds, Fetched: 2 row(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;上述建表语句中，通过对 student.txt 文件结构化文件的分析，先通过逗号 “，” 对多个字段 fields 进行分隔；接着，针对 hobby 字段列，通过横线 “-” 进行集合列分隔；最后，再针对每一个爱好，通过冒号 “：” 进行分隔为最终的 “key：value” 形式。执行上述建表语句后，就会在默认的 /user/hive/warehouse/zjdf.db 文件夹下生成一个 t_student 文件夹。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://gitee.com/vickyFish/typora_pic/raw/master/images/image-20211201235638917.png&#34; alt=&#34;image-20211201235638917&#34; /&gt;&lt;/p&gt;
&lt;p&gt;此时，还必须将前面的结构化文件 student.txt 上传到该文件夹下进行映射，才能生成对应的内部表数据，上传完成后再次查询生成的 t_student 表信息。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;# vi student.txt&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;# cat student.txt &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;1,zhangsan,唱歌:非常喜欢-跳舞:喜欢-游泳:一般般&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2,lisi,打游戏:非常喜欢-篮球:不喜欢&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;# hadoop fs -put student.txt /user/hive/warehouse/zjdf.db/t_student&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21/12/01 10:15:07 WARN util.NativeCodeLoader: Unable to load native-hadoop library &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; your platform... using builtin-java classes &lt;span class=&#34;built_in&#34;&gt;where&lt;/span&gt; applicable&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;再次在 hive 中查询 t_student 数据表格，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; select * from t_student;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;1	zhangsan	&amp;#123;&amp;quot;唱歌&amp;quot;:&amp;quot;非常喜欢&amp;quot;,&amp;quot;跳舞&amp;quot;:&amp;quot;喜欢&amp;quot;,&amp;quot;游泳&amp;quot;:&amp;quot;一般般&amp;quot;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2	lisi	&amp;#123;&amp;quot;打游戏&amp;quot;:&amp;quot;非常喜欢&amp;quot;,&amp;quot;篮球&amp;quot;:&amp;quot;不喜欢&amp;quot;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.082 seconds, Fetched: 2 row(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&#34;hive外部表操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hive外部表操作&#34;&gt;#&lt;/a&gt; Hive 外部表操作&lt;/h2&gt;
&lt;p&gt;内部表，即不添加关键字 External，内部表与结构化数据文件要想产生关系映射，那么数据文件就必须在指定的内部表文件夹下，而当遇到大文件的情况时，移动数据文件非常耗时，这就需要我们来创建外部表，因为它不需要移动结构化数据文件。下面我们通过一个小案例来，对外部表进行讲解。&lt;/p&gt;
&lt;p&gt;现有结构化数据文件 student.txt，且数据内容如文件所示。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;95001,李勇,男,20,CS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95002,刘晨,女,19,IS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95003,王敏,女,22,MA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95004,张立,男,19,IS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95005,刘刚,男,18,MA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95006,孙庆,男,23,CS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95007,易思玲,女,19,MA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95008,李娜,女,18,CS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95009,梦圆圆,女,18,MA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95010,孔小涛,男,19,CS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95011,包小柏,男,18,MA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95012,孙花,女,20,CS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95013,冯伟,男,21,CS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95014,王小丽,女,19,CS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95015,王君,男,18,MA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95016,钱国,男,21,MA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95017,王风娟,女,18,IS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95018,王一,女,19,IS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95019,邢小丽,女,19,IS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95020,赵钱,男,21,IS&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95021,周二,男,17,MA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;95022,郑明,男,20,MA&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;首先，我们将 student.txt 文件上传至 HDFS 上的 /stu 路径下，用来模拟生产环境下的数据文件，具体命令如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# vi student.txt &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# hadoop fs -mkdir /stu&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21/12/01 10:21:27 WARN util.NativeCodeLoader: Unable to load native-hadoop library &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; your platform... using builtin-java classes &lt;span class=&#34;built_in&#34;&gt;where&lt;/span&gt; applicable&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# hadoop fs -put student.txt /stu&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21/12/01 10:22:05 WARN util.NativeCodeLoader: Unable to load native-hadoop library &lt;span class=&#34;keyword&#34;&gt;for&lt;/span&gt; your platform... using builtin-java classes &lt;span class=&#34;built_in&#34;&gt;where&lt;/span&gt; applicable&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在 hive 中创建外部表&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; create external table student_ext(Sno int,Sname string,Sex string,Sage int,Sdept string) row format delimited fields terminated by &amp;#39;,&amp;#39; location &amp;#39;&amp;#x2F;stu&amp;#39;;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.041 seconds&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; show tables;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;student_ext&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;t_student&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;t_user&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.027 seconds, Fetched: 3 row(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;从结果发现，student_ext 外部表已经创建成功，最后，HQL（HiveQL）对数据表的内容的查看、增加、删除以及修改的语句均与 SQL 语句一致。下面以查看数据表内容为例进行演示，具体语法如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; select * from student_ext;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;结果如下&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://gitee.com/vickyFish/typora_pic/raw/master/images/image-20211202001146733.png&#34; alt=&#34;image-20211202001146733&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小提示：Hive 创建内部表时，会将数据移动到数据库指向的路径；创建外部表时，仅记录数据所在的路径，不会对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;hive分区表操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hive分区表操作&#34;&gt;#&lt;/a&gt; Hive 分区表操作&lt;/h2&gt;
&lt;p&gt;分区表是按照属性在文件夹层面给文件更好的管理，实际上就是对应一个 HDFS 文件系统上的独立文件夹，该文件夹下是该分区所有的数据文件。Hive 中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集。在查询时通过 WHERE 子句中的表达式选择查询指定的分区，这样的查询效率会提高很多。Hive 分区表一共有两种，分别为普通分区和动态分区，我们下面就要对其分别进行介绍。&lt;/p&gt;
&lt;h3 id=&#34;hive普通分区&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hive普通分区&#34;&gt;#&lt;/a&gt; Hive 普通分区&lt;/h3&gt;
&lt;p&gt;创建分区表分为两种，一种是单分区，也就是说在表文件夹目录下只有一级文件夹目录。另外一种是多分区，表文件夹下出现多文件夹嵌套模式，现在我们只针对单分区进行详解，若想学习多分区可以参考官网的官方文档。&lt;/p&gt;
&lt;p&gt;现有结构化数据文件 user_p.txt，文件中的数据内容如文件所示。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1,allen&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2,tom&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3,jerry&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# mkdir -p /export/data/hivedata/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# cd /export/data/hivedata/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;# ll&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;total 8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;-rw-r--r--. 1 root root 109 Dec  1 10:14 student.txt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;-rw-r--r--. 1 root root  31 Dec  1 09:43 user.txt&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;# vi user_p.txt&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;首先，创建分区表。语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; create table t_user_p(id int, name string) partitioned by (country string) row format delimited fields terminated by &amp;#39;,&amp;#39;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;https://gitee.com/vickyFish/typora_pic/raw/master/images/image-20211202002144514.png&#34; alt=&#34;image-20211202002144514&#34; /&gt;&lt;/p&gt;
&lt;p&gt;其次，加载数据是将数据文件移动到与 Hive 表对应的位置，从本地（Linux）复制或移动到 HDFS 文件系统的操作。由于分区表在映射数据时不能使用 Hadoop 命令移动文件，需要使用 Load 命令，其语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;LOAD DATA [LOCAL] INPATH &amp;#39;filepath&amp;#39; [OVERWRITE] &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;INTO TABLE table_name [PARTITION (partcol1&amp;#x3D;val1, partcol2&amp;#x3D;val2 ...)]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Load Data 是 HQL 固定的数据装载语句，下面针对部分关键字进行讲解。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filepath：它可以引用一个文件（在这种情况下，Hive 将文件移动到表所对应的目录中），或者它可以是一个目录（在这种情况下，Hive 将把该目录中的所有文件移动到表所对应的目录中）。它可以是相对路径、绝对路径以及完整的 URI。&lt;/li&gt;
&lt;li&gt;Local：如果指定了 Local 键字，Load 命令将在本地文件系统（Hive 服务启动方）中查找文件路径，将其复制到对应的 HDFS 路径下；如果没有指定 Local 关键字，它将会从 HDFS 中移动数据文件至对应的表路径下。&lt;/li&gt;
&lt;li&gt;Overwrite：如果使用了 Overwrite 关键字，当加载数据时目标表或分区中的内容会被删除，然后再将 filepath 指向的文件或目录中的内容添加到表或分区中。简单的说就是覆盖表中已有数据；若不添加该关键字，则表示追加数据内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;加载数据操作的语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; load data local inpath &amp;#39;&amp;#x2F;export&amp;#x2F;data&amp;#x2F;hivedata&amp;#x2F;user_p.txt&amp;#39; into table t_user_p partition(country&amp;#x3D;&amp;#39;USA&amp;#39;);&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Loading data to table zjdf.t_user_p partition (country&amp;#x3D;USA)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Partition zjdf.t_user_p&amp;#123;country&amp;#x3D;USA&amp;#125; stats: [numFiles&amp;#x3D;1, numRows&amp;#x3D;0, totalSize&amp;#x3D;22, rawDataSize&amp;#x3D;0]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.618 seconds&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;从上述语句看出，Load Data 表示装载数据，Inpath 表示数据文件所在的本地系统路径，partition（country=‘USA’）为指定的分区，它需要与建表时设置的分区字段保持一致。执行完上述命令后，查看表内容的数据，效果如图所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; select * from t_user_p;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;1	allen	USA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2	tom	USA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3	jerry	USA&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.274 seconds, Fetched: 3 row(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;hive动态分区&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hive动态分区&#34;&gt;#&lt;/a&gt; Hive 动态分区&lt;/h3&gt;
&lt;p&gt;上面介绍了 Hive 普通分区的创建和 Load 命令加载数据的操作。在默认情况下，我们加载数据时，需要手动的设置分区字段，并且针对一个分区就要写一个插入语句。如果源数据量很大时（例如，现有许多日志文件，要求按照日期作为分区字段，在插入数据的时候无法手动的添加分区），就可以利用 Hive 提供的动态分区，可以简化插入数据时的繁琐操作，若想实现动态分区，则需要开启动态分区功能，具体命令如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive&amp;gt; set hive.exec.dynamic.partition&amp;#x3D;true;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive&amp;gt; set hive.exec.dynamic.partition.mode&amp;#x3D;nonstrict;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;Hive 默认是不支持动态分区的，因此 hive.exec.dynamic.partition 默认值为 false，需要启动动态分区功能，可以将该参数设置为 true；其中 hive.exec.dynamic.partition.mode 的默认值是 strict，表示必须指定至少一个分区为静态分区，将此参数修改为 nonstrict，表示允许所有的分区字段都可以使用动态分区。&lt;/p&gt;
&lt;p&gt;在 Hive 中 insert 语句是用于动态插入数据的，不同的是它主要是结合 select 查询语句使用，且非常适用于动态分区插入数据，语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive&amp;gt; insert overwrite table table_name &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;partition (partcol1[&amp;#x3D;val1], partcol2[&amp;#x3D;val2] ...) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;select_statement FROM from_statement&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;现有原始表的结构化数据文件 dynamic_partition_table.txt，内容数据如文件所示。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;2018-05-10,ip1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-05-10,ip2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-14,ip3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-14,ip4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-15,ip1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-15,ip2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;# vi dynamic_partition_table.txt&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;# cat dynamic_partition_table.txt &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-05-10,ip1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-05-10,ip2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-14,ip3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-14,ip4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-15,ip1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-15,ip2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master hivedata]&lt;span class=&#34;comment&#34;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;现在我们通过一个案例进行演示动态分区的数据插入操作。将 dynamic_partition_table 中的数据按照时间（day），插入到目标表 d_p_t 的相应分区中。&lt;/p&gt;
&lt;p&gt;首先，创建原始表。语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; create table dynamic_partition_table(day string,ip string) row format delimited fields terminated by &amp;quot;,&amp;quot;;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.05 seconds&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; show tables;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dynamic_partition_table&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;student_ext&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;t_student&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;t_user&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;t_user_p&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.033 seconds, Fetched: 5 row(s)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;其次，加载数据文件至原始表，语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; load data local inpath &amp;#39;&amp;#x2F;export&amp;#x2F;data&amp;#x2F;hivedata&amp;#x2F;dynamic_partition_table.txt&amp;#39; into table dynamic_partition_table;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Loading data to table zjdf.dynamic_partition_table&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Table zjdf.dynamic_partition_table stats: [numFiles&amp;#x3D;1, totalSize&amp;#x3D;90]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.234 seconds&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; select * from dynamic_partition_table;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-05-10	ip1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-05-10	ip2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-14	ip3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-14	ip4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-15	ip1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2018-06-15	ip2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.062 seconds, Fetched: 6 row(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;再次，创建目标表，语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; create table d_p_t(ip string) partitioned by (month string,day string);&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.045 seconds&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; show tables;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;d_p_t&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;dynamic_partition_table&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;student_ext&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;t_student&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;t_user&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;t_user_p&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.023 seconds, Fetched: 6 row(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;依次，动态插入，语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; insert overwrite table d_p_t partition (month,day) select ip,substr(day,1,7) as month,day from dynamic_partition_table;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;C:/Users/yujz/AppData/Roaming/Typora/typora-user-images/image-20211202004106877.png&#34; alt=&#34;image-20211202004106877&#34; /&gt;&lt;/p&gt;
&lt;p&gt;最后，查看目标表中的分区数据，语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt; show partitions d_p_t;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;month&amp;#x3D;2018-05&amp;#x2F;day&amp;#x3D;2018-05-10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;month&amp;#x3D;2018-06&amp;#x2F;day&amp;#x3D;2018-06-14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;month&amp;#x3D;2018-06&amp;#x2F;day&amp;#x3D;2018-06-15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.449 seconds, Fetched: 3 row(s)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive (zjdf)&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h2 id=&#34;hive桶表操作&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hive桶表操作&#34;&gt;#&lt;/a&gt; Hive 桶表操作&lt;/h2&gt;
&lt;p&gt;为了将表进行更细粒度的范围划分，我们可以创建桶表。桶表，是根据某个属性字段把数据分成几个桶（我们这里设置为 4，默认值是 - 1，可自定义），也就是在文件的层面上把数据分开。下面通过一个案例进行桶表相关操作的演示。&lt;/p&gt;
&lt;p&gt;首先，我们先开启分桶功能，命令如下所示。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive&amp;gt; set hive.enforce.bucketing &amp;#x3D; true;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&amp;#x2F;&amp;#x2F;由于HQL最终会转成MR程序，所以分桶数与ReduceTask数保持一致，&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&amp;#x2F;&amp;#x2F;从而产生相应的文件个数&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive&amp;gt; set mapreduce.job.reduces&amp;#x3D;4;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;其次，创建桶表，语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive&amp;gt; create table stu_buck(Sno int,Sname string,Sex string,Sage int,Sdept string) clustered by(Sno) into 4 buckets row format delimited fields terminated by &amp;#39;,&amp;#39;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;执行上述语句后，桶表 stu_buck 创建完成，并且以学生编号（Sno）分为 4 个桶，以 “，” 为分隔符的桶表。&lt;/p&gt;
&lt;p&gt;再次，在 HDFS 的 /stu/ 目录下已有结构化数据文件 student.txt，我们需要将 student.txt 文件的复制到 /hivedata 目录下。然后，加载数据到桶表中，由于分桶表加载数据时，不能使用 Load Data 方式导入数据（原因在于该 Load Data 本质上是对数据文件进行复制或移动到 Hive 表所对应的地址中），因此在分桶表导入数据时需要创建临时的 student 表，该表与 stu_buck 表的字段必须一致，语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive&amp;gt; create table student_tmp(Sno int,Sname string,Sex string,Sage int,Sdept string) &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;row format delimited fields terminated by &amp;#39;,&amp;#39;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;依次，加载数据至 student 表，语法格式如下所示&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive&amp;gt; load data local inpath &amp;#39;&amp;#x2F;hivedata&amp;#x2F;student.txt&amp;#39; into table student_tmp;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;最后，将数据导入 stu_buck 表，语法格式如下所示：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;hive&amp;gt; insert overwrite table stu_buck select * from student_tmp cluster by(Sno);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;总体来说，分桶表是把表所映射的结构化数据分得更细致，且分桶规则与 MapReduce 分区规则一致，Hive 采用对目标列值进行哈希运算，得到哈希值再与桶个数取模的方式决定数据的归并，从而看出 Hive 与 MapReduce 存在紧密联系。使用分桶可以提高查询效率，例如执行 Join 操作时，两个表有相同的列字段，如果对这两张表都采取了分桶操作，那么就可以减少 Join 操作时的数据量，从而提高查询效率。它还能够在处理大规模数据集时，选择小部分数据集进行抽样运算，从而减少资源浪费。&lt;/p&gt;
</content>
        <category term="大数据技术与应用" />
        <category term="Hive" />
        <updated>2021-12-01T16:49:21.872Z</updated>
    </entry>
    <entry>
        <id>http://example.com/2021/11/30/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/Hive%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/</id>
        <title>Hive安装教程</title>
        <link rel="alternate" href="http://example.com/2021/11/30/%E5%9C%A8%E7%BA%BF%E8%AF%BE%E7%A8%8B/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8/Hive%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
        <content type="html">&lt;h1 id=&#34;hive的安装&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#hive的安装&#34;&gt;#&lt;/a&gt; Hive 的安装&lt;/h1&gt;
&lt;p&gt;​	本地和远程模式安装配置方式大致相同，本质上是将 Hive 默认的元数据存储介质由自带的 Derby 数据库替换为 MySQL 数据库，这样无论在任何目录下以任何方式启动 Hive，只要连接的是同一台 Hive 服务，那么所有节点访问的元数据信息是一致的，从而实现元数据的共享。下面就以本地模式为例，讲解安装过程。&lt;br /&gt;
​	本地模式的 Hive 安装主要包括两个步骤：首先安装 MySQL 服务，再安装 Hive。具体步骤如下：&lt;/p&gt;
&lt;h2 id=&#34;安装mysql服务&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#安装mysql服务&#34;&gt;#&lt;/a&gt; 安装 MySQL 服务&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;MySQL安装方式有许多种，可以直接解压安装包进行相关配置，也可以选择在线安装，本节选用在线安装MySQL方式。在线安装MySQL的具体指令和说明如下：
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;切换yum源&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#切换yum源&#34;&gt;#&lt;/a&gt; 切换 yum 源&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;命令行提示符&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# vi /etc/yum.repos.d/CentOS-Base.repo&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br /&gt;
 修改镜像的内容，一定要确定修改的是正确并且完整，修改的文本内容如下，删除的时候可以在命令模式下输入【100dd】快速删除，操作演示如下：&lt;br /&gt;
&lt;img data-src=&#34;https://media.giphy.com/media/CdThtgNMrtTPh23QKN/source.gif&#34; alt=&#34;&#34; /&gt;&lt;br /&gt;
​	需要修改的 yum 镜像文件如下也可以在下发的文件中进行复制：&lt;br /&gt;
&lt;figure class=&#34;highlight txt&#34;&gt;&lt;figcaption&gt;&lt;span&gt;yum镜像文件&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;36&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[base]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;name=CentOS-6.10 - Base - mirrors.aliyun.com&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;failovermethod=priority&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;baseurl=http://mirrors.aliyun.com/centos-vault/6.10/os/$basearch/&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gpgcheck=1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;#released updates &lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[updates]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;name=CentOS-6.10 - Updates - mirrors.aliyun.com&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;failovermethod=priority&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;baseurl=http://mirrors.aliyun.com/centos-vault/6.10/updates/$basearch/&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gpgcheck=1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;#additional packages that may be useful&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[extras]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;name=CentOS-6.10 - Extras - mirrors.aliyun.com&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;failovermethod=priority&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;baseurl=http://mirrors.aliyun.com/centos-vault/6.10/extras/$basearch/&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gpgcheck=1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;#additional packages that extend functionality of existing packages&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[centosplus]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;name=CentOS-6.10 - Plus - mirrors.aliyun.com&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;failovermethod=priority&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;baseurl=http://mirrors.aliyun.com/centos-vault/6.10/centosplus/$basearch/&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gpgcheck=1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;enabled=0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;#contrib - packages by Centos Users&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[contrib]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;name=CentOS-6.10 - Contrib - mirrors.aliyun.com&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;failovermethod=priority&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;baseurl=http://mirrors.aliyun.com/centos-vault/6.10/contrib/$basearch/&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gpgcheck=1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;enabled=0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;gpgkey=http://mirrors.aliyun.com/centos-vault/RPM-GPG-KEY-CentOS-6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;清除yum缓存&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#清除yum缓存&#34;&gt;#&lt;/a&gt; 清除 yum 缓存&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;Bash命令&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# yum clean all&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br /&gt;
&lt;img data-src=&#34;https://i.loli.net/2021/11/30/jdJSKHGmwD97g5b.jpg&#34; alt=&#34;hive1.jpg&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;在线安装mysql软件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#在线安装mysql软件&#34;&gt;#&lt;/a&gt; 在线安装 MySql 软件&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;Bash命令&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# yum -y install mysql-server&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br /&gt;
​	安装完成后，如图片所示，则数据库安装完成：&lt;br /&gt;
&lt;img data-src=&#34;https://i.loli.net/2021/11/30/oPD2nesHX7tJ9jy.jpg&#34; alt=&#34;hive2.jpg&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;启动mysql服务&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#启动mysql服务&#34;&gt;#&lt;/a&gt; 启动 mysql 服务&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;Bash命令&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# service mysqld start&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# chkconfig mysqld on&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br /&gt;
&lt;img data-src=&#34;https://i.loli.net/2021/11/30/ZCIJv4xWKR53Dap.jpg&#34; alt=&#34;hive3.jpg&#34; /&gt;&lt;br /&gt;
​	上述指令中，首先通过 “yum install” 命令下载并安装 MySQL 程序，并且启动 MySQL 服务，然后就可以使用 MySQL 命令连接到 MySQL 客户端。&lt;strong&gt;需要注意的是，上述安装与启动 MySQL 程序仅限于 Centos6 中使用。&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;说明&lt;/strong&gt;：如果是 CentOS7 可以参考：&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9zZWdtZW50ZmF1bHQuY29tL2EvMTE5MDAwMDAyMjI0NTg1OQ==&#34;&gt;Centos7 在线安装和配置 MySQL5.7 - SegmentFault 思否&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&#34;修改登录mysql用户名和密码bash&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#修改登录mysql用户名和密码bash&#34;&gt;#&lt;/a&gt; 修改登录 MySQL 用户名和密码 bash&lt;/h3&gt;
&lt;p&gt;​	进入 mysql 数据库&lt;br /&gt;
 &lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;Bash命令&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# mysql&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br /&gt;
&lt;img data-src=&#34;https://i.loli.net/2021/11/30/6f2azJbwBKVpAsn.jpg&#34; alt=&#34;hive4.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;highlight plain&#34;&gt;&lt;figcaption&gt;&lt;span&gt;数据库界面&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;mysql&amp;gt; set password for root@localhost&amp;#x3D;password(&amp;#39;123456&amp;#39;);&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Query OK, 0 rows affected (0.00 sec)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mysql&amp;gt; GRANT ALL PRIVILEGES ON *.* TO &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED BY &amp;#39;123456&amp;#39; WITH GRANT OPTION;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Query OK, 0 rows affected (0.00 sec)&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;mysql&amp;gt; FLUSH PRIVILEGES;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Query OK, 0 rows affected (0.00 sec)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br /&gt;
​	结果显示如下：&lt;br /&gt;
&lt;img data-src=&#34;https://i.loli.net/2021/11/30/aHubCKIYEwZ1RVc.jpg&#34; alt=&#34;hive5.jpg&#34; /&gt;&lt;br /&gt;
​	运行结束后，【ctrl+c】退出 mysql 数据库！&lt;/p&gt;
&lt;h2 id=&#34;安装hive&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#安装hive&#34;&gt;#&lt;/a&gt; 安装 Hive&lt;/h2&gt;
&lt;h3 id=&#34;上传hive安装包并解压&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#上传hive安装包并解压&#34;&gt;#&lt;/a&gt; 上传 Hive 安装包并解压&lt;/h3&gt;
&lt;p&gt;​	创建出存放 hive 软件的目录和安装的目录，切换至 &lt;code&gt;software&lt;/code&gt;  目录，将软件包拖放至此，然后在进行解压到 &lt;code&gt;servers&lt;/code&gt; 。&lt;br /&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;Bash命令&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# mkdir -p /export/software/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# mkdir -p /export/servers/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# cd /export/software/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master software]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br /&gt;
​	打开 &lt;code&gt;新建文件传输&lt;/code&gt; 图标，如下所示：&lt;br /&gt;
&lt;img data-src=&#34;https://i.loli.net/2021/11/30/C2ZpIGaFubx1w5E.jpg&#34; alt=&#34;hive6.jpg&#34; /&gt;&lt;br /&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;Bash命令&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master software]&lt;span class=&#34;comment&#34;&gt;# tar -zxvf apache-hive-1.2.1-bin.tar.gz -C /export/servers/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br /&gt;
​	&lt;strong&gt;一定要确定是解压成功之后在操作，解压成功会有如下信息显示。&lt;/strong&gt;&lt;br /&gt;
&lt;img data-src=&#34;https://i.loli.net/2021/11/30/boZ3HIk2WvY8Bgq.jpg&#34; alt=&#34;hive7.jpg&#34; /&gt;&lt;/p&gt;
&lt;h3 id=&#34;修改配置文件&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#修改配置文件&#34;&gt;#&lt;/a&gt; 修改配置文件&lt;/h3&gt;
&lt;p&gt;​	首先，切换目录到 hive 配置文件目录下，由于 Hive 安装包 conf 目录下，没有提供 hive-site.xml 文件，这里需要创建并编辑一个 hive-site.xml 配置文件，具体内容如下所示：&lt;br /&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;Bash命令&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master servers]&lt;span class=&#34;comment&#34;&gt;# cd /export/servers/apache-hive-1.2.1-bin/conf/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master conf]&lt;span class=&#34;comment&#34;&gt;# vi hive-site.xml&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br /&gt;
​	将以下配置信息粘贴进去，并保存退出。&lt;br /&gt;
&lt;figure class=&#34;highlight xml&#34;&gt;&lt;figcaption&gt;&lt;span&gt;hive配置文件&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;configuration&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionURL&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;Mysql连接协议&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionDriverName&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;com.mysql.jdbc.Driver&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;JDBC连接驱动&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionUserName&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;root&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;用户名&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionPassword&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;123456&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;        &lt;span class=&#34;tag&#34;&gt;&amp;lt;&lt;span class=&#34;name&#34;&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;密码&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;description&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;  &lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;tag&#34;&gt;&amp;lt;/&lt;span class=&#34;name&#34;&gt;configuration&lt;/span&gt;&amp;gt;&lt;/span&gt;	 &lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;依赖包的更换&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#依赖包的更换&#34;&gt;#&lt;/a&gt; 依赖包的更换&lt;/h3&gt;
&lt;p&gt;​	将桌面的 &lt;code&gt;mysql-connector-java-5.1.21.jar&lt;/code&gt; Mysql 驱动包放到 &lt;code&gt;/export/servers/apache-hive-1.2.1-bin/lib&lt;/code&gt;  目录中，如下图所示：&lt;br /&gt;
&lt;img data-src=&#34;https://i.loli.net/2021/11/30/O9w4fybUYhj7vsF.jpg&#34; alt=&#34;hive8.jpg&#34; /&gt;&lt;br /&gt;
​	开两个 &lt;code&gt;新建文件传输窗口&lt;/code&gt; 将 Hadoop 中的 Jline 包替换成 hive 包中 Jline 包，并将&lt;strong&gt; Hadoop 中旧的 Jline 包版本删除，一定要删除，否则还是旧版本。&lt;/strong&gt;&lt;br /&gt;
&lt;img data-src=&#34;https://i.loli.net/2021/11/30/UE6eOuVZBP9Lzts.jpg&#34; alt=&#34;hive9.jpg&#34; /&gt;&lt;br /&gt;
&lt;strong&gt; 注意：如果拖不过去的话，就先将 Jline 包拖放到桌面，然后再放进 Hadoop 文件夹中。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;启动hadoop集群&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#启动hadoop集群&#34;&gt;#&lt;/a&gt; 启动 Hadoop 集群&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;Bash命令&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master conf]&lt;span class=&#34;comment&#34;&gt;# sh /usr/local/hadoop-2.6.5/sbin/start-all.sh&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;WARNING: HADOOP_SECURE_DN_USER has been replaced by HDFS_DATANODE_SECURE_USER. Using value of HADOOP_SECURE_DN_USER.&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Starting namenodes on [master]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Last login: Thu Nov 25 05:04:04 CST 2021 from 192.168.128.1 on pts/0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Starting datanodes&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Last login: Thu Nov 25 05:43:45 CST 2021 on pts/0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Starting secondary namenodes [master]&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Last login: Thu Nov 25 05:43:48 CST 2021 on pts/0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Starting resourcemanager&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Last login: Thu Nov 25 05:43:53 CST 2021 on pts/0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Starting nodemanagers&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Last login: Thu Nov 25 05:44:00 CST 2021 on pts/0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master ~]&lt;span class=&#34;comment&#34;&gt;# jps&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;1824 SecondaryNameNode&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2375 Jps&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2059 ResourceManager&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;1566 NameNode&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br /&gt;
 初始化 Mysql 元数据&lt;br /&gt;
 &lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;Bash命令&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master conf]&lt;span class=&#34;comment&#34;&gt;# cd /export/servers/apache-hive-1.2.1-bin/bin/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;[root@master bin]&lt;span class=&#34;comment&#34;&gt;# ./schematool -dbType mysql -initSchema&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Metastore connection URL:	 jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=&lt;span class=&#34;literal&#34;&gt;true&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Metastore Connection Driver :	 com.mysql.jdbc.Driver&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Metastore connection User:	 root&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Starting metastore schema initialization to 1.2.0&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Initialization script hive-schema-1.2.0.mysql.sql&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Initialization script completed&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;schemaTool completed&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&#34;启动hive&#34;&gt;&lt;a class=&#34;anchor&#34; href=&#34;#启动hive&#34;&gt;#&lt;/a&gt; 启动 Hive&lt;/h3&gt;
&lt;p&gt;&lt;figure class=&#34;highlight bash&#34;&gt;&lt;figcaption&gt;&lt;span&gt;Bash命令&lt;/span&gt;&lt;/figcaption&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;[root@master bin]&lt;span class=&#34;comment&#34;&gt;# ./hive&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Logging initialized using configuration &lt;span class=&#34;keyword&#34;&gt;in&lt;/span&gt; jar:file:/&lt;span class=&#34;built_in&#34;&gt;export&lt;/span&gt;/servers/apache-hive-1.2.1-bin/lib/hive-common-1.2.1.jar!/hive-log4j.properties&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;hive&amp;gt; show databases;&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;OK&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;default&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;Time taken: 0.901 seconds, Fetched: 1 row(s)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br /&gt;
​	到此为止，Hive 已经安装完成！！&lt;/p&gt;
</content>
        <category term="大数据技术与应用" />
        <category term="Hive" />
        <updated>2021-11-30T14:51:49.025Z</updated>
    </entry>
</feed>
